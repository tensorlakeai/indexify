# Indexify

![Tests](https://github.com/diptanu/indexify/actions/workflows/test.yaml/badge.svg?branch=main)

Indexify is a knowledge and memory retrieval service for Large Language Models. It facilitates in-context learning of LLMs by providing relevant context in a prompt or exposing relevant memory to AI agents.

Indexify has a built in data parallel content extraction engine which enables scalable extraciton of content using AI models to keep indexes updated in real time(or re-index with a new model) as data is ingested.

## Why use Indexify
**Knowledge Base for LLMs:** Real time retrieval of knowledge and context from private documents and structured data to improve accuracy of LLM models.

**Memory Engine for Co-Pilot agents:** Store and retrieve long-term memory of agents in real-time, providing enhanced personalization and improved user experiences for co-pilot and chat based applications.

**Distributed Extraction Engine For Scale:** Distributed extraction to scale indexing large amount of data without sacrificing retrieval performance.

**Custom Extractors:** You can extend Indexify by writing a custom extractor for your use cases to extract specific information from data.

## Getting Started

To get started follow our [documentation](https://getindexify.ai/getting_started/).

## Documentation

Our comprehensive documentation is available - https://getindexify.ai

## Contributions
Please open an issue to discuss new features, or join our Discord group. Contributions are welcome, there are a bunch of open tasks we could use help with! 

If you want to contribute on the Rust codebase, please read the [developer readme](docs/docs/develop.md).

## Contact 
Join the Discord Server - https://discord.gg/mrXrq3DmV8 <br />

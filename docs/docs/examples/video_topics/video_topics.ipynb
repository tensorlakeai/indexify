{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Debate Topic-wise Summary Pipeline with Indexify and Mistral\n",
    "\n",
    "In this cookbook, we'll explore how to create a debate topic-wise summary pipeline using Indexify and Mistral's large language models. By the end of this document, you'll have a pipeline capable of processing video debates, extracting audio, performing speech recognition and diarization, and generating summaries for each topic discussed.\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "1. [Introduction](#introduction)\n",
    "2. [Prerequisites](#prerequisites)\n",
    "3. [Setup](#setup)\n",
    "   - [Install Indexify](#install-indexify)\n",
    "   - [Install Required Extractors](#install-required-extractors)\n",
    "4. [Creating the Extraction Graph](#creating-the-extraction-graph)\n",
    "5. [Implementing the Debate Summary Pipeline](#implementing-the-debate-summary-pipeline)\n",
    "6. [Running the Summary Pipeline](#running-the-summary-pipeline)\n",
    "7. [Customization and Advanced Usage](#customization-and-advanced-usage)\n",
    "8. [Conclusion](#conclusion)\n",
    "\n",
    "## Introduction\n",
    "\n",
    "The debate summary pipeline will consist of four main steps:\n",
    "1. Video to Audio extraction using `tensorlake/audio-extractor`\n",
    "2. Speech recognition and diarization using `tensorlake/asrdiarization`\n",
    "3. Topic extraction using `tensorlake/mistral`\n",
    "4. Topic-wise summarization using `tensorlake/mistral`\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "Before we begin, ensure you have the following:\n",
    "\n",
    "- Create a virtual env with Python 3.9 or later\n",
    "  ```shell\n",
    "  python3.9 -m venv ve\n",
    "  source ve/bin/activate\n",
    "  ```\n",
    "- `pip` (Python package manager)\n",
    "- A Mistral API key\n",
    "- Basic familiarity with Python and command-line interfaces\n",
    "\n",
    "## Setup\n",
    "\n",
    "### Install Indexify\n",
    "\n",
    "First, let's install Indexify using the official installation script:\n",
    "\n",
    "```bash\n",
    "curl https://getindexify.ai | sh\n",
    "```\n",
    "\n",
    "Start the Indexify server:\n",
    "```bash\n",
    "./indexify server -d\n",
    "```\n",
    "\n",
    "### Install Required Extractors\n",
    "\n",
    "Next, we'll install the necessary extractors in a new terminal:\n",
    "\n",
    "```bash\n",
    "pip install indexify-extractor-sdk\n",
    "indexify-extractor download tensorlake/audio-extractor\n",
    "indexify-extractor download tensorlake/asrdiarization\n",
    "indexify-extractor download tensorlake/mistral\n",
    "```\n",
    "\n",
    "Once the extractors are downloaded, start them:\n",
    "```bash\n",
    "indexify-extractor join-server\n",
    "```\n",
    "\n",
    "## Creating the Extraction Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from indexify import IndexifyClient, ExtractionGraph\n",
    "\n",
    "client = IndexifyClient()\n",
    "\n",
    "extraction_graph_spec = \"\"\"\n",
    "name: 'debate_summarizer'\n",
    "extraction_policies:\n",
    "  - extractor: 'tensorlake/audio-extractor'\n",
    "    name: 'video_to_audio'\n",
    "  - extractor: 'tensorlake/asrdiarization'\n",
    "    name: 'speech_recognition'\n",
    "    content_source: 'video_to_audio'\n",
    "  - extractor: 'tensorlake/mistral'\n",
    "    name: 'topic_extraction'\n",
    "    input_params:\n",
    "      model_name: 'mistral-large-latest'\n",
    "      key: 'YOUR_MISTRAL_API_KEY'\n",
    "      system_prompt: 'Extract the main topics discussed in this debate transcript. List each topic as a brief phrase or title.'\n",
    "    content_source: 'speech_recognition'\n",
    "  - extractor: 'tensorlake/mistral'\n",
    "    name: 'topic_summarization'\n",
    "    input_params:\n",
    "      model_name: 'mistral-large-latest'\n",
    "      key: 'YOUR_MISTRAL_API_KEY'\n",
    "      system_prompt: 'Summarize the discussion on the main topics from the debate transcript. Provide key points and arguments from both sides.'\n",
    "    content_source: 'speech_recognition'\n",
    "\"\"\"\n",
    "\n",
    "extraction_graph = ExtractionGraph.from_yaml(extraction_graph_spec)\n",
    "client.create_extraction_graph(extraction_graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace `'YOUR_MISTRAL_API_KEY'` with your actual Mistral API key.\n",
    "\n",
    "## Implementing the Debate Summary Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from indexify import IndexifyClient\n",
    "\n",
    "def summarize_debate(video_path):\n",
    "    client = IndexifyClient()\n",
    "    \n",
    "    # Upload the video file\n",
    "    content_id = client.upload_file(\"debate_summarizer\", video_path)\n",
    "    \n",
    "    # Wait for the extraction to complete\n",
    "    client.wait_for_extraction(content_id)\n",
    "    \n",
    "    # Retrieve the extracted topics\n",
    "    topics = client.get_extracted_content(\n",
    "        content_id=content_id,\n",
    "        graph_name=\"debate_summarizer\",\n",
    "        policy_name=\"topic_extraction\"\n",
    "    )\n",
    "    \n",
    "    topics = topics[0]['content'].decode('utf-8')\n",
    "    \n",
    "    summaries = client.get_extracted_content(\n",
    "        content_id=content_id,\n",
    "        graph_name=\"debate_summarizer\",\n",
    "        policy_name=\"topic_summarization\"\n",
    "    )\n",
    "\n",
    "    summaries = summaries[0]['content'].decode('utf-8')\n",
    "    \n",
    "    return topics, summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for extraction to complete for content id:  f70ff53b532fbba0\n"
     ]
    }
   ],
   "source": [
    "video_path = \"biden_trump_debate_2024.mp4\"\n",
    "    \n",
    "topics, summaries = summarize_debate(video_path)\n",
    "\n",
    "print(\"Debate Topics and Summaries:\")\n",
    "print(topics, summaries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will process the video, extract topics, and generate summaries for each topic discussed in the debate.\n",
    "\n",
    "## Customization and Advanced Usage\n",
    "\n",
    "You can customize the summarization process by modifying the `system_prompt` in the extraction graph. For example:\n",
    "\n",
    "- To focus on specific aspects of the debate:\n",
    "  ```yaml\n",
    "  system_prompt: 'Summarize the candidate positions and key policy differences on the following topic from the debate transcript:'\n",
    "  ```\n",
    "\n",
    "- To generate more concise summaries:\n",
    "  ```yaml\n",
    "  system_prompt: 'Provide a brief, bullet-point summary of the main arguments on the following topic from the debate transcript:'\n",
    "  ```\n",
    "\n",
    "You can also experiment with different Mistral models by changing the `model_name` parameter to find the best balance between speed and accuracy for your specific use case.\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "This debate topic-wise summary pipeline demonstrates the power and flexibility of Indexify for complex, multi-step processing tasks. Key advantages include:\n",
    "\n",
    "1. **Scalability**: Indexify can handle large video files and process multiple debates efficiently.\n",
    "2. **Modularity**: Each step in the pipeline (audio extraction, speech recognition, topic extraction, summarization) is separate, allowing for easy customization and improvement.\n",
    "3. **Error Handling**: Indexify automatically retries failed steps, ensuring robustness in processing.\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "- Explore more Indexify features in the [official documentation](https://docs.getindexify.ai)\n",
    "- Learn about other use cases, such as [entity extraction from documents](https://github.com/mistralai/cookbook/tree/main/third_party/Indexify/pdf-entity-extraction)\n",
    "- Experiment with different extractors and language models to improve the accuracy and depth of your debate summaries"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorlake",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

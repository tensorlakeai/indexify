{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "364d8936-4b1f-4ab4-a197-16a8a91ddfdf",
   "metadata": {},
   "source": [
    "# **Accurate Image RAG using Yolo and CodeGemma**\n",
    "\n",
    "<div class=\"align-center\">\n",
    "  <a href=\"https://getindexify.ai/\"><img src=\"https://getindexify.ai/Indexify_Logo_Wordmark.svg\" width=\"145\"></a>\n",
    "  <a href=\"https://discord.com/invite/kF8UZACA7r\"><img src=\"https://raw.githubusercontent.com/rishiraj/random/main/Discord%20button.png\" width=\"145\"></a><br>\n",
    "  Join Discord if you need help + ⭐ <i>Star us on <a href=\"https://github.com/tensorlakeai/indexify\">Github</a></i> ⭐\n",
    "</div>\n",
    "\n",
    "Most Language Models(especially smaller ones) don't have vision capabilities. In this example, we will augment them with vision capabilities by automatically injecting structured data from images. The pipeline is tested to work at any scale, on laptops and with 10s of 1000s images on the cloud.\n",
    "\n",
    "What happens behind the scenes:\n",
    "\n",
    "1. Indexify extracts and automatically populates structured data from images as they are ingested.\n",
    "2. The LLM is presented with the schema of the underlying schema for it to retrieve data based on the question\n",
    "3. Indexify client retrieves the information based on the generated SQL schema and provides the necessary information to the LLM."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67d58697",
   "metadata": {},
   "source": [
    "## **Setup**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e29561-367f-43df-897e-d159f553021d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install indexify langchain langchain_community\n",
    "\n",
    "# Download Indexify Server\n",
    "!curl https://getindexify.ai | sh\n",
    "\n",
    "# Download Extractors\n",
    "!indexify-extractor download tensorlake/yolo-extractor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b573a399",
   "metadata": {},
   "source": [
    "After installing the necessary libraries, download the server, and the extractors, you need to restart the runtime. Then, you have to run Indexify Server with the Extractors.\n",
    "\n",
    "Open 2 terminals and run the following commands:\n",
    "\n",
    "```bash\n",
    "# Terminal 1\n",
    "./indexify server -d\n",
    "\n",
    "# Terminal 2\n",
    "indexify-extractor join-server\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17f19446",
   "metadata": {},
   "source": [
    "## **Create Extraction Graph**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "2b6dc1c3-90af-4f53-93a5-07ffb3957ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from indexify import IndexifyClient\n",
    "client = IndexifyClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c3049bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "extraction_graph_spec = \"\"\"\n",
    "name: \"image\"\n",
    "extraction_policies:\n",
    "   - extractor: \"tensorlake/yolo-extractor\"\n",
    "     name: \"object_detection\"\n",
    "\"\"\"\n",
    "\n",
    "extraction_graph = ExtractionGraph.from_yaml(extraction_graph_spec)\n",
    "client.create_extraction_graph(extraction_graph)                                            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "0df93f40-eb92-40bf-9742-b7cdd470b166",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'CREATE TABLE IF NOT EXISTS \"ingestion\" (\"content_id\" TEXT NULL, \"bounding_box\" LIST NULL, \"object_name\" TEXT NULL);'"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schema = client.list_schemas()[\"ddls\"][\"ingestion\"]\n",
    "schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "a8197d2c-144b-4932-8c93-ae4233ce8e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.ingest_remote_file(\n",
    "    \"image\",\n",
    "    \"https://extractor-files.diptanu-6d5.workers.dev/images/Central_Park_Lake.jpg\",\n",
    "    \"image/png\",\n",
    "    { \"location\": \"central park\" }\n",
    ")\n",
    "\n",
    "content_id = response[\"content_id\"]\n",
    "client.wait_for_extraction(content_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "b762595a-9bc5-4414-ba3a-6ab0f7c609c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_community.llms import Ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "41a674b7-97a7-4565-ac46-f6cc9a6905b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask(prompt, question):\n",
    "    model = Ollama(model=\"codegemma\")\n",
    "    chain = (\n",
    "        {\"question\": RunnablePassthrough()}\n",
    "        | prompt\n",
    "        | model\n",
    "        | StrOutputParser()\n",
    "    )\n",
    "\n",
    "    return chain.invoke(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "767f0154-ed64-4029-a953-e2f33333b32f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generatate_sql_from_question(question):\n",
    "    template = f\"\"\"\n",
    "    Images are stored in the database with the following schema:\n",
    "    {schema}\n",
    "\n",
    "    fyi. \n",
    "\n",
    "    Generate the SQL query as raw text, without any explanation, based on the following question below:\n",
    "    1. Generate only the raw SQL statement as text\n",
    "    2. Please don't add any backticks in the response \n",
    "    3. The object_name column has entity name of the object detected in the content. The values can be person, boat, bulb, etc.\n",
    "    4. Add predicates appropiately\n",
    "\n",
    "    \"\"\" + \"Question: {question}\"\n",
    "    prompt = ChatPromptTemplate.from_template(template)\n",
    "    generated_sql = ask(prompt, question)\n",
    "    print(f\"Generated SQL: {generated_sql}\")\n",
    "    return generated_sql\n",
    "\n",
    "\n",
    "def run_sql(query):\n",
    "    query_result = client.sql_query(query)\n",
    "    query_result = pformat(query_result.result).replace('{', '').replace('}', '')\n",
    "    return query_result\n",
    "\n",
    "\n",
    "def answer_from_results(question, generated_sql, query_result):\n",
    "    template = f\"\"\"\n",
    "    The question user asked is:\n",
    "    {question}\n",
    "    We ran a database query:  {generated_sql}\n",
    "    The query returned the result: {query_result}\n",
    "\n",
    "    FYI. \n",
    "\n",
    "    \"\"\"\n",
    "    prompt = ChatPromptTemplate.from_template(template)\n",
    "    return ask(prompt, question)\n",
    "\n",
    "\n",
    "def ask_question(question):\n",
    "    sql_query = generatate_sql_from_question(question)\n",
    "    results = run_sql(sql_query)\n",
    "    answer = answer_from_results(question, sql_query, results)\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "c9754fcc-f900-4a32-a65b-3b852ee26dbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated SQL: SELECT COUNT(*)\n",
      "FROM ingestion\n",
      "WHERE content_id = 'mbntU1flW0qZFZSl' AND object_name = 'person';\n",
      "The query returned a result of 13, indicating that there are 13 people in content_id: mbntU1flW0qZFZSl.\n"
     ]
    }
   ],
   "source": [
    "response = ask_question(f\"how many people are in content_id: {content_id}?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "559cca5d-d8d5-4960-b694-2ac877aba485",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_names=[\n",
    "    \"skate.jpg\", \"congestion.jpg\", \"bushwick-bred.jpg\",\n",
    "    \"141900.jpg\", \"132500.jpg\", \"123801.jpg\",\n",
    "    \"120701.jpg\", \"103701.jpg\"\n",
    "]\n",
    "\n",
    "file_urls = [f\"https://extractor-files.diptanu-6d5.workers.dev/images/{file_name}\" for file_name in file_names]\n",
    "for file_url in file_urls:\n",
    "    client.ingest_remote_file(file_url, \"image/png\", {})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "22235d09-466f-4b03-926d-f4ed68a5bfa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated SQL: SELECT content_id, COUNT(*) AS num_boats\n",
      "FROM ingestion\n",
      "WHERE object_name = 'boat'\n",
      "GROUP BY content_id;\n",
      "Based on the provided query results, the content_id with boat and the number of boats in each photo are:\n",
      "\n",
      "| content_id | num_boats |\n",
      "|---|---|\n",
      "| mbntU1flW0qZFZSl | 8 |\n",
      "| B4jdKmmKzlg3buza | 15 |\n",
      "| 8mtV1EXpnLl4_1jS | 6 |\n",
      "| E3eZbhOSRhWQ6aCE | 18 |\n"
     ]
    }
   ],
   "source": [
    "response = ask_question(\"List all the content_id with boat and also print the number of boats in each of the photos?\")\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

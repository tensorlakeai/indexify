{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "defe2f2f",
   "metadata": {},
   "source": [
    "## **Setup**\n",
    "\n",
    "<div class=\"align-center\">\n",
    "  <a href=\"https://getindexify.ai/\"><img src=\"https://getindexify.ai/Indexify_Logo_Wordmark.svg\" width=\"145\"></a>\n",
    "  <a href=\"https://discord.com/invite/kF8UZACA7r\"><img src=\"https://raw.githubusercontent.com/rishiraj/random/main/Discord%20button.png\" width=\"145\"></a><br>\n",
    "  Join Discord if you need help + ⭐ <i>Star us on <a href=\"https://github.com/tensorlakeai/indexify\">Github</a></i> ⭐\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6751dae7-4f17-4d4f-9b36-cc57915806d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pydantic indexify indexify-extractor-sdk\n",
    "\n",
    "\n",
    "# Download Indexify Server\n",
    "!curl https://getindexify.ai | sh\n",
    "\n",
    "# Download Extractors\n",
    "!indexify-extractor download tensorlake/instructor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20537a48",
   "metadata": {},
   "source": [
    "After installing the necessary libraries, download the server, and the extractors, you need to restart the runtime. Then, you have to run Indexify Server with the Extractors.\n",
    "\n",
    "Open 2 terminals and run the following commands:\n",
    "\n",
    "```bash\n",
    "# Terminal 1\n",
    "./indexify server -d\n",
    "\n",
    "# Terminal 2\n",
    "indexify-extractor join-server\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5617e2bc",
   "metadata": {},
   "source": [
    "## **Create Extraction Pipeline**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c62996ab-48fb-4a63-a7de-7223ddb61f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class Extraction(BaseModel):\n",
    "    topic: str\n",
    "    summary: str\n",
    "    hypothetical_questions: List[str] = Field(\n",
    "        default_factory=list,\n",
    "        description=\"Hypothetical questions that this document could answer\",\n",
    "    )\n",
    "    keywords: List[str] = Field(\n",
    "        default_factory=list, description=\"Keywords that this document is about\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c3197573-7d6a-4741-82fc-4ba9fd15674a",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_chunk = \"\"\"\n",
    "## Simple RAG\n",
    "\n",
    "****What is it?****\n",
    "\n",
    "The simplest implementation of RAG embeds a user query and do a single embedding search in a vector database, like a vector store of Wikipedia articles. However, this approach often falls short when dealing with complex queries and diverse data sources.\n",
    "\n",
    "**What are the limitations?**\n",
    "\n",
    "- **Query-Document Mismatch:** It assumes that the query and document embeddings will align in the vector space, which is often not the case.\n",
    "    - Query: \"Tell me about climate change effects on marine life.\"\n",
    "    - Issue: The model might retrieve documents related to general climate change or marine life, missing the specific intersection of both topics.\n",
    "- **Monolithic Search Backend:** It relies on a single search method and backend, reducing flexibility and the ability to handle multiple data sources.\n",
    "    - Query: \"Latest research in quantum computing.\"\n",
    "    - Issue: The model might only search in a general science database, missing out on specialized quantum computing resources.\n",
    "- **Text Search Limitations:** The model is restricted to simple text queries without the nuances of advanced search features.\n",
    "    - Query: \"what problems did we fix last week\"\n",
    "    - Issue: cannot be answered by a simple text search since documents that contain problem, last week are going to be present at every week.\n",
    "- **Limited Planning Ability:** It fails to consider additional contextual information that could refine the search results.\n",
    "    - Query: \"Tips for first-time Europe travelers.\"\n",
    "    - Issue: The model might provide general travel advice, ignoring the specific context of first-time travelers or European destinations.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b6dc1c3-90af-4f53-93a5-07ffb3957ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from indexify import IndexifyClient\n",
    "client = IndexifyClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "736d511a-991d-43f2-8627-4334ab970a21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Extractor(name=tensorlake/instructor, description=Instructor Extractor, input_params={'properties': {'instructions': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'default': None, 'title': 'Instructions'}, 'model': {'default': 'gpt-3.5-turbo', 'title': 'Model', 'type': 'string'}, 'schema_bytes': {'format': 'binary', 'title': 'Schema Bytes', 'type': 'string'}, 'system_message': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'default': None, 'title': 'System Message'}}, 'required': ['schema_bytes'], 'title': 'InputParams', 'type': 'object'}, input_mime_types=['text/plain'], outputs={'model': {'metadata': {'age': {'comment': None, 'type': 'int'}, 'name': {'comment': None, 'type': 'text'}, 'place': {'comment': None, 'type': 'text'}}}})]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.extractors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c146f9-6863-406f-ac26-70866cc661fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cloudpickle\n",
    "import base64\n",
    "import json\n",
    "\n",
    "extraction_model = base64.b64encode(cloudpickle.dumps(Extraction))\n",
    "extraction_model = extraction_model.decode('utf-8')\n",
    "\n",
    "extraction_graph_spec = f\"\"\"\n",
    "name: \"instructor\"\n",
    "extraction_policies:\n",
    "  - extractor: \"tensorlake/instructor\"\n",
    "    name: \"extract_chunks\"\n",
    "    input_params:\n",
    "      - schema_bytes: {extraction_model}\n",
    "      - system_message: \"Your role is to extract chunks from the following and create a set of topics.\"\n",
    "\"\"\"\n",
    "\n",
    "extraction_graph = ExtractionGraph.from_yaml(extraction_graph_spec)\n",
    "client.create_extraction_graph(extraction_graph)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "1de2ae1d-666b-45c9-8aba-129f0d9a2f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "content_id = client.add_documents(\"instructor\", text_chunk)\n",
    "client.wait_for_extraction(content_id)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

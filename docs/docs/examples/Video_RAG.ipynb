{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4081e41e",
   "metadata": {},
   "source": [
    "# **RAG using Video as Context**\n",
    "\n",
    "This notebook will guide you on creating a RAG pipeline with a video as the knowledge source. The pipeline will be able to answer questions based on the video content."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4510d4a",
   "metadata": {},
   "source": [
    "## **Setup**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb2e12a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install indexify indexify-extractor-sdk pytube indexify-langchain langchain langchain-openai\n",
    "\n",
    "# Download Indexify Server\n",
    "!curl https://www.tensorlake.ai | sh\n",
    "\n",
    "# Download Extractors\n",
    "!indexify-extractor download hub://audio/whisper-asr\n",
    "!indexify-extractor download hub://video/audio-extractor\n",
    "!indexify-extractor download hub://text/chunking\n",
    "!indexify-extractor download hub://embedding/minilm-l6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a1dd2c7",
   "metadata": {},
   "source": [
    "After installing the necessary libraries, download the server, and the extractors, you need to restart the runtime. Then, you have to run Indexify Server with the Extractors.\n",
    "\n",
    "Open 2 terminals and run the following commands:\n",
    "\n",
    "```bash\n",
    "# Terminal 1\n",
    "./indexify server -d\n",
    "\n",
    "# Terminal 2\n",
    "indexify-extractor join-server\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b11da9a",
   "metadata": {},
   "source": [
    "## **RAG Pipeline**\n",
    "\n",
    "In Indexify, we need to create an Extraction Graph to extract the information from the video. Think of it as a pipeline that will process the video and extract the necessary information.\n",
    "\n",
    "For this example, we will use the following extraction policies:\n",
    "1. Extract the audio from the video (`audio-extractor`)\n",
    "2. Transcribe the audio to text (`whisper-asr`)\n",
    "3. Chunk the text into paragraphs (`chunk-extractor`)\n",
    "4. Generate the embeddings and index the paragraphs (`minilm-l6`)\n",
    "\n",
    "Extraction Policies: How we extract the information from a data source."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e9d03366-a86b-402e-856e-082c74e41620",
   "metadata": {},
   "outputs": [],
   "source": [
    "from indexify import IndexifyClient, ExtractionGraph\n",
    "client = IndexifyClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "736d511a-991d-43f2-8627-4334ab970a21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Extractor(name=tensorlake/audio-extractor, description=Extract audio from video, input_params={'properties': {}, 'title': 'AudioExtractorConfig', 'type': 'object'}, input_mime_types=['video', 'video/mp4', 'video/mov', 'video/avi'], outputs={}),\n",
       " Extractor(name=tensorlake/chunk-extractor, description=Text Chunk Extractor, input_params={'properties': {'chunk_size': {'default': 100, 'title': 'Chunk Size', 'type': 'integer'}, 'headers_to_split_on': {'default': [], 'items': {'type': 'string'}, 'title': 'Headers To Split On', 'type': 'array'}, 'overlap': {'default': 0, 'title': 'Overlap', 'type': 'integer'}, 'text_splitter': {'default': 'recursive', 'enum': ['char', 'recursive', 'markdown', 'html'], 'title': 'Text Splitter', 'type': 'string'}}, 'title': 'ChunkExtractionInputParams', 'type': 'object'}, input_mime_types=['text/plain'], outputs={}),\n",
       " Extractor(name=tensorlake/minilm-l6, description=MiniLM-L6 Sentence Transformer, input_params=None, input_mime_types=['text/plain'], outputs={'embedding': {'embedding': {'dim': 384, 'distance': 'cosine'}}}),\n",
       " Extractor(name=tensorlake/whisper-asr, description=Whisper ASR, input_params={'properties': {'chunk_length': {'default': 30, 'title': 'Chunk Length', 'type': 'integer'}, 'max_new_tokens': {'default': 128, 'title': 'Max New Tokens', 'type': 'integer'}}, 'title': 'InputParams', 'type': 'object'}, input_mime_types=['audio', 'audio/mpeg'], outputs={})]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.extractors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e9882f22-2bec-49cc-a72a-94b5b6786544",
   "metadata": {},
   "outputs": [],
   "source": [
    "extraction_graph_spec = \"\"\"\n",
    "name: \"video-knowledgebase\"\n",
    "extraction_policies:\n",
    "   - extractor: \"tensorlake/audio-extractor\"\n",
    "     name: \"audio_clips\"\n",
    "\n",
    "   - extractor: \"tensorlake/whisper-asr\"\n",
    "     name: \"transcription\"\n",
    "     content_source: \"audio_clips\"\n",
    "\n",
    "   - extractor: \"tensorlake/chunk-extractor\"\n",
    "     name: \"transcription_chunks\"\n",
    "     input_params:\n",
    "        chunk_size: 1000\n",
    "        overlap: 250\n",
    "     content_source: \"transcription\"\n",
    "\n",
    "   - extractor: \"tensorlake/minilm-l6\"\n",
    "     name: \"transcription-embedding\"\n",
    "     content_source: \"transcription_chunks\"\n",
    "\"\"\"\n",
    "\n",
    "extraction_graph = ExtractionGraph.from_yaml(extraction_graph_spec)\n",
    "client.create_extraction_graph(extraction_graph)                                            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72031464",
   "metadata": {},
   "source": [
    "## **Upload Video to Indexify**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3197573-7d6a-4741-82fc-4ba9fd15674a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytube import YouTube\n",
    "import os\n",
    "yt = YouTube(\"https://www.youtube.com/watch?v=cplSUhU2avc\")\n",
    "file_name = \"state_of_the_union_2024.mp4\"\n",
    "if not os.path.exists(file_name):\n",
    "    video = yt.streams.filter(progressive=True, file_extension=\"mp4\").order_by(\"resolution\").desc().first()\n",
    "    video.download(filename=file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8197d2c-144b-4932-8c93-ae4233ce8e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.upload_file(extraction_graphs=\"video-knowledgebase\", path=\"state_of_the_union.mp4\")       "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4df561d",
   "metadata": {},
   "source": [
    "## **RAG with Indexify**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "767f0154-ed64-4029-a953-e2f33333b32f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from indexify_langchain import IndexifyRetriever\n",
    "\n",
    "params = {\n",
    "    \"name\": \"video-knowledgebase.transcription-embedding.embedding\",\n",
    "    \"top_k\": 50\n",
    "}\n",
    "\n",
    "retriever = IndexifyRetriever(client=client, params=params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "284e1c0c-30e1-4b25-a3dd-c6edb6b27593",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "125f6d88-015f-4cf5-8c8f-4006f72438cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"Answer the question based only on the following context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "model = ChatOpenAI(openai_api_key=\"xxx\")\n",
    "chain = (\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1447bdf4-b905-4b5a-bdd0-a79f3fa36008",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Biden is taking significant action on climate by cutting carbon emissions in half by 2030, creating clean energy jobs, launching the Climate Corps, and working towards environmental justice. He mentions that the world is facing a climate crisis and that all Americans deserve the freedom to be safe. Biden also mentions that America is safer today than when he took office and provides statistics on murder rates and violent crime decreasing.'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\"Whats President Biden doing to save climate and the evidences he provides?\")        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

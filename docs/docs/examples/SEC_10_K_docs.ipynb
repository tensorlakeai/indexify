{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# **Introduction**\n",
        "\n",
        "This notebook demonstrates how Indexify can make it easier to quickly extract insights from complex SEC filings like the Form 10-K annual report. Using Uber's 10-K as an example, we show how the Indexify library can enable question answering on the filing text to get rapid answers. We also illustrate how schema-based extraction can pull key data points from the unstructured document. The combination of question answering and schema-based extraction provides a powerful toolkit to derive insights from dense financial filings."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r9NVuXFG3qGw"
      },
      "source": [
        "## **Setup**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install indexify indexify-extractor-sdk\n",
        "\n",
        "# Download Indexify Server\n",
        "!curl https://getindexify.ai | sh\n",
        "\n",
        "# Install Poppler (required for PDF extraction)\n",
        "# You can use brew on MacOS.\n",
        "!sudo apt-get install -y poppler-utils\n",
        "\n",
        "# Download Extractors\n",
        "!indexify-extractor download hub://text/chunking\n",
        "!indexify-extractor download hub://embedding/minilm-l6\n",
        "!indexify-extractor download hub://pdf/pdf-extractor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KEHbUyCM3-vm"
      },
      "source": [
        "After installing the necessary libraries, download the server, and the extractors, you need to restart the runtime. Then, you have to run Indexify Server with the Extractors.\n",
        "\n",
        "Open 2 terminals and run the following commands:\n",
        "\n",
        "```bash\n",
        "# Terminal 1\n",
        "./indexify server -d\n",
        "\n",
        "# Terminal 2\n",
        "indexify-extractor join-server\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **Test the extractors**\n",
        "\n",
        "We will try PDFExtractor first. The PDFExtractor can extract all the values from text as well as tables in one shot and passes it to the next chained extractors which can be used for question answering.\n",
        "\n",
        "We'll start by downloading Uber's Form 10-K report."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "import requests\n",
        "req = requests.get(\"https://d18rn0p25nwr6d.cloudfront.net/CIK-0001543151/6fabd79a-baa9-4b08-84fe-deab4ef8415f.pdf\")\n",
        "\n",
        "with open('form10-k.pdf','wb') as f:\n",
        "    f.write(req.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from indexify_extractor_sdk import load_extractor, Content\n",
        "\n",
        "pdfextractor, pdfconfig_cls = load_extractor(\"indexify_extractors.pdf-extractor.pdf_extractor:PDFExtractor\")\n",
        "content = Content.from_file(\"form10-k.pdf\")\n",
        "config = pdfconfig_cls()\n",
        "\n",
        "pdf_result = pdfextractor.extract(content, config)\n",
        "text_content = next(content.data.decode('utf-8') for content in pdf_result if content.content_type == 'text/plain')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "UNITED STATES\n",
            "SECURITIES AND EXCHANGE COMMISSION\n",
            "Washington, D.C. 20549\n",
            "____________________________________________ \n",
            "FORM 10-K\n",
            "____________________________________________ \n",
            "(Mark One)\n",
            "☒ ANNUAL REPORT PURSUANT TO SECTION 13 OR 15(d) OF THE SECURITIES EXCHANGE ACT OF 1934\n",
            "For the fiscal year ended December 31, 2023\n",
            "OR\n",
            "☐ TRANSITION REPORT PURSUANT TO SECTION 13 OR 15(d) OF THE SECURITIES EXCHANGE ACT OF 1934\n",
            "For the transition period from_____ to _____            \n",
            "Commission File Number: 001-38902\n",
            "____________________________________________ \n",
            "UBER TECHNOLOGIES, INC.\n",
            "(Exact name of registrant as specified in its charter)\n",
            "____________________________________________ \n",
            "Delaware\n",
            "45-2647441\n",
            "(State or other jurisdiction of incorporation or organization)\n",
            "(I.R.S. Employer Identification No.)\n",
            "1725 3rd Street\n",
            "San Francisco, California 94158\n",
            "(Address of principal executive offices, including zip code)\n",
            "(415) 612-8582\n",
            "(Registrant’s telephone number, including area code)\n",
            " ____________________________________________\n",
            "Securities registered pursuant to Section 12(b) of the Act:\n",
            "Title of each class\n",
            "Trading Symbol(s)\n",
            "Name of each exchange on which registered\n",
            "Common Stock, par value $0.00001 per share\n",
            "UBER\n",
            "New York Stock Exchange\n",
            "Securities registered pursuant to Section 12(g) of the Act: None\n",
            "Indicate by check mark whether the registrant is a well-known seasoned issuer, as defined in Rule 405 of the Securities Act. Yes  ☒ No ☐\n",
            "Indicate by check mark whether the registrant is not required to file reports pursuant to Section 13 or Section 15(d) of the Act. Yes  ☐ No  ☒\n",
            "Indicate by check mark whether the registrant (1) has filed all reports required to be filed by Section 13 or 15(d) of the Securities Exchange Act of 1934 during the\n",
            "preceding 12 months (or for such shorter period that the registrant was required to file such reports), and (2) has been subject to such filing requirements for the\n",
            "past 90 days. Yes  ☒ No ☐\n",
            "Indicate by check mark whether the registrant has submitted electronically every Interactive Data File required to be submitted pursuant to Rule 405 of Regulation\n",
            "S-T (§232.405 of this chapter) during the preceding 12 months (or for such shorter period that the registrant was required to submit such files). Yes  ☒ No ☐\n",
            "Indicate by check mark whether the registrant is a large accelerated filer, an accelerated filer, a non-accelerated filer, a smaller reporting company, or an emerging\n",
            "growth company. See the definitions of “large accelerated filer,” “accelerated filer,” “smaller reporting company,” and “emerging growth company” in Rule 12b-2\n",
            "of the Exchange Act.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(text_content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sTIlKuPp6wxg"
      },
      "source": [
        "## **Create a Client**\n",
        "Instantiate the Indexify Client"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "HZNysNl-631k"
      },
      "outputs": [],
      "source": [
        "from indexify import IndexifyClient\n",
        "client = IndexifyClient()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **1. Question Answering Task**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GQr1749x6_CW"
      },
      "source": [
        "### **Extraction Graph Setup**\n",
        "\n",
        "1. Import the `ExtractionGraph` class from the `indexify` package.\n",
        "\n",
        "2. Define the extraction graph specification in YAML format:\n",
        "   - Set the name of the extraction graph to \"pdfqa\".\n",
        "   - Define the extraction policies:\n",
        "     - Use the \"tensorlake/pdf-extractor\" extractor for PDF marking and name it \"docextractor\".\n",
        "     - Use the \"tensorlake/chunk-extractor\" for text chunking and name it \"chunks\".\n",
        "       - Set the input parameters for the chunker:\n",
        "         - `chunk_size`: 1000 (size of each text chunk)\n",
        "         - `overlap`: 100 (overlap between chunks)\n",
        "         - `content_source`: \"docextractor\" (source of content for chunking)\n",
        "     - Use the \"tensorlake/minilm-l6\" extractor for embedding and name it \"get-embeddings\".\n",
        "       - Set the content source for embedding to \"chunks\".\n",
        "\n",
        "3. Create an `ExtractionGraph` object from the YAML specification using `ExtractionGraph.from_yaml()`.\n",
        "\n",
        "4. Create the extraction graph on the Indexify client using `client.create_extraction_graph()`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "from indexify import ExtractionGraph\n",
        "\n",
        "extraction_graph_spec = \"\"\"\n",
        "name: 'pdfqa'\n",
        "extraction_policies:\n",
        "   - extractor: 'tensorlake/pdf-extractor'\n",
        "     name: 'docextractor'\n",
        "   - extractor: 'tensorlake/chunk-extractor'\n",
        "     name: 'chunker'\n",
        "     input_params:\n",
        "        chunk_size: 1000\n",
        "        overlap: 100\n",
        "     content_source: 'docextractor'\n",
        "   - extractor: 'tensorlake/minilm-l6'\n",
        "     name: 'embedder'\n",
        "     content_source: 'chunker'\n",
        "\"\"\"\n",
        "\n",
        "extraction_graph = ExtractionGraph.from_yaml(extraction_graph_spec)\n",
        "client.create_extraction_graph(extraction_graph)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZGqpkx3P7gsh"
      },
      "source": [
        "### **Upload the FORM 10-K PDF File**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "ETideBqK8GGp"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'357d5a0d5e9a7d30'"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "content_id = client.upload_file(\"pdfqa\", \"form10-k.pdf\")\n",
        "client.wait_for_extraction(content_id)  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I2WDexIU8LFy"
      },
      "source": [
        "### **What is happening behind the scenes**\n",
        "\n",
        "Indexify is designed to seamlessly respond to ingestion events by assessing all existing policies and triggering the necessary extractors for extraction. Once the PDF extractor completes the process of extracting texts, bytes, and JSONs from the document, it automatically initiates the embedding extractor to chunk the content, extract embeddings, and populate an index.\n",
        "\n",
        "With Indexify, you have the ability to upload hundreds of PDF files simultaneously, and the platform will efficiently handle the extraction and indexing of the contents without requiring manual intervention. To expedite the extraction process, you can deploy multiple instances of the extractors, and Indexify's built-in scheduler will transparently distribute the workload among them, ensuring optimal performance and efficiency."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B6SQ0xDt9a_9"
      },
      "source": [
        "### **Perform RAG with OpenAI**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "2raD6aeB9Th1"
      },
      "outputs": [],
      "source": [
        "def get_context(question: str, index: str, top_k=3):\n",
        "    results = client.search_index(name=index, query=question, top_k=top_k)\n",
        "    context = \"\"\n",
        "    for result in results:\n",
        "        context = context + f\"content id: {result['content_id']} \\n\\n passage: {result['text']}\\n\"\n",
        "    return context"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'content id: 42c552ac1b572bd3 \\n\\n passage: harm to the acquired company’s brand.\\nIn addition, our acquisition of Careem has increased our risks under the U.S. Foreign Corrupt Practices Act (“FCPA”) and other similar laws outside the United\\nStates. Our existing and planned safeguards, including training and compliance programs to discourage corrupt practices by such parties, may not prove effective,\\nand such parties may engage in conduct for which we could be held responsible.\\nWe may not receive a favorable return on investment for prior or future business combinations, and we cannot predict whether these transactions will be\\naccretive to the value of our common stock. It is also possible that acquisitions, combinations, divestitures, joint ventures, or other strategic transactions we\\nannounce could be viewed negatively by the press, investors, platform users, or regulators, any or all of which may adversely affect our reputation and our\\ncontent id: 5c647fd06e97f75a \\n\\n passage: by the release of the valuation allowance due to deferred tax liabilities recorded as a result of the acquisitions providing an additional source of taxable income to\\nsupport the realizability of pre-existing deferred tax assets.\\nFor the year ended December 31, 2022, the increase in the valuation allowance was primarily attributable to an increase in deferred tax assets resulting from\\nthe loss from operations, offset by the deferred tax impact from the transfer of certain intangible assets among our wholly-owned subsidiaries.\\nITEM 9. CHANGES IN AND DISAGREEMENTS WITH ACCOUNTANTS ON ACCOUNTING AND FINANCIAL DISCLOSURE\\nNone.\\nITEM 9A. CONTROLS AND PROCEDURES\\nEvaluation of Disclosure Controls and Procedures\\nWe maintain disclosure controls and procedures that are designed to provide reasonable assurance that information required to be disclosed in reports that we\\ncontent id: 24992794bef930f6 \\n\\n passage: authorizations of management and directors of the company; and (iii) provide reasonable assurance regarding prevention or timely detection of unauthorized\\nacquisition, use, or disposition of the company’s assets that could have a material effect on the financial statements.\\nBecause of its inherent limitations, internal control over financial reporting may not prevent or detect misstatements. Also, projections of any evaluation of\\neffectiveness to future periods are subject to the risk that controls may become inadequate because of changes in conditions, or that the degree of compliance with\\nthe policies or procedures may deteriorate.\\n71\\n'"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "question = \"What are the disclosure with respect to Foreign Subsidiaries?\"\n",
        "context = get_context(question, \"pdfqa.embedder.embedding\")\n",
        "context"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_prompt(question, context):\n",
        "    return f\"Answer the question, based on the context.\\n question: {question} \\n context: {context}\"\n",
        "\n",
        "prompt = create_prompt(question, context)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "from openai import OpenAI\n",
        "client_openai = OpenAI()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ckexWnEe-B3c"
      },
      "source": [
        "Now ask any question related to the ingested FORM 10-K PDF document"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "cSc4uBLA-IEB"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The disclosures with respect to Foreign Subsidiaries include risks under the U.S. Foreign Corrupt Practices Act and other similar laws, potential negative impacts on reputation from acquisitions or strategic transactions, and the evaluation of controls and procedures to prevent unauthorized acquisition, use, or disposition of assets.\n"
          ]
        }
      ],
      "source": [
        "chat_completion = client_openai.chat.completions.create(\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": prompt,\n",
        "        }\n",
        "    ],\n",
        "    model=\"gpt-3.5-turbo\",\n",
        ")\n",
        "print(chat_completion.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **2. Schema-based Retrieval Task**\n",
        "Alert: The following example will cost a lot of OpenAI credits. Move ahead at your own risk."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **Extraction Graph Setup**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "extraction_graph_spec = \"\"\"\n",
        "name: 'pdfschema'\n",
        "extraction_policies:\n",
        "   - extractor: 'tensorlake/pdf-extractor'\n",
        "     name: 'docextractor'\n",
        "   - extractor: 'tensorlake/schema'\n",
        "     name: 'schemaprocessor'\n",
        "     input_params:\n",
        "        service: 'openai'\n",
        "        schema: {'properties': {'file_number': {'title': 'File Number', 'type': 'string'}, 'registrant_name': {'title': 'Registrant Name', 'type': 'string'}, 'jurisdiction': {'title': 'Jurisdiction', 'type': 'string'}, 'employer_id_number': {'title': 'Employer Id Number', 'type': 'string'}, 'address': {'title': 'Address', 'type': 'string'}, 'telephone_number': {'title': 'Telephone Number', 'type': 'string'}, 'title_of_each_class': {'title': 'Title Of Each Class', 'type': 'string'}, 'trading_symbol': {'title': 'Trading Symbol', 'type': 'string'}, 'name_of_exchange': {'title': 'Name Of Exchange', 'type': 'string'}}, 'required': ['file_number', 'registrant_name', 'jurisdiction', 'employer_id_number', 'address', 'telephone_number', 'title_of_each_class', 'trading_symbol', 'name_of_exchange'], 'title': 'Form', 'type': 'object'}\n",
        "     content_source: 'docextractor'\n",
        "\"\"\"\n",
        "\n",
        "extraction_graph = ExtractionGraph.from_yaml(extraction_graph_spec)\n",
        "client.create_extraction_graph(extraction_graph)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **Upload the FORM 10-K PDF File**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'6c898c11de955629'"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "content_id = client.upload_file(\"pdfschema\", \"form10-k.pdf\")\n",
        "client.wait_for_extraction(content_id)  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **View the extracted content**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "client.get_extracted_content('6c898c11de955629')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

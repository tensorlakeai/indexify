{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Transcribing Audio and Question Answering with ASR, Diarization, and Retrieval-Augmented Generation**\n",
    "\n",
    "<div class=\"align-center\">\n",
    "  <a href=\"https://getindexify.ai/\"><img src=\"https://getindexify.ai/Indexify_Logo_Wordmark.svg\" width=\"145\"></a>\n",
    "  <a href=\"https://discord.com/invite/kF8UZACA7r\"><img src=\"https://raw.githubusercontent.com/rishiraj/random/main/Discord%20button.png\" width=\"145\"></a><br>\n",
    "  Join Discord if you need help + ⭐ <i>Star us on <a href=\"https://github.com/tensorlakeai/indexify\">Github</a></i> ⭐\n",
    "</div>\n",
    "\n",
    "This notebook demonstrates a powerful pipeline for transcribing audio, such as podcasts, and performing question answering using Retrieval-Augmented Generation (RAG). The pipeline combines Automatic Speech Recognition (ASR), diarization, and speculative decoding techniques to efficiently process audio data and generate informative responses.\n",
    "\n",
    "## Key Components\n",
    "\n",
    "1. **ASR**: We employ a state-of-the-art ASR model to convert audio into text transcriptions. The ASR pipeline is modularized, allowing flexibility in use cases where diarization may not be required.\n",
    "\n",
    "2. **Diarization**: Built on top of the ASR outputs, our diarization pipeline utilizes the Pyannote model, currently a leading open-source implementation. Diarization enables speaker identification and separation within the transcribed audio.\n",
    "\n",
    "3. **Speculative Decoding**: To accelerate inference, we incorporate speculative decoding. This technique uses a smaller, faster assistant model to propose generations that are then validated by the larger main model.\n",
    "\n",
    "4. **Retrieval-Augmented Generation (RAG)**: By leveraging the transcribed and diarized audio, we apply RAG to perform question answering. RAG combines information retrieval techniques with generation models to produce accurate and contextually relevant responses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Install Indexify, Start the Server & Download the Extractors**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q -U indexify indexify-extractor-sdk\n",
    "\n",
    "# Download Indexify Server\n",
    "!curl https://getindexify.ai | sh\n",
    "\n",
    "# Download Extractors\n",
    "!indexify-extractor download hub://audio/asrdiarization\n",
    "!indexify-extractor download hub://text/chunking\n",
    "!indexify-extractor download hub://embedding/arctic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After installing the necessary libraries, download the server, and the extractors, you need to restart the runtime. Then, you have to run Indexify Server with the Extractors.\n",
    "\n",
    "**Open 2 terminals and run the following commands:**\n",
    "\n",
    "```bash\n",
    "# Terminal 1\n",
    "./indexify server -d\n",
    "\n",
    "# Terminal 2\n",
    "indexify-extractor join-server\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Create a Client, Define Extraction Graph & Ingest Contents**\n",
    "\n",
    "Instantiate the Indexify Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from indexify import IndexifyClient\n",
    "client = IndexifyClient()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Import the `ExtractionGraph` class from the `indexify` package.\n",
    "\n",
    "2. Define the extraction graph specification in YAML format:\n",
    "   - Set the name of the extraction graph to \"transcribe\".\n",
    "   - Define the extraction policies:\n",
    "     - Use the \"tensorlake/asrdiarization\" extractor for speech to text, specify its parameters and name it \"sttextractor\".\n",
    "     - Use the \"tensorlake/chunk-extractor\" for text chunking, specify its parameters, name it \"chunker\" and connect to \"sttextractor\".\n",
    "     - Use the \"tensorlake/minilm-l6\" extractor for embedding, name it \"embedder\" and connect to \"chunker\".\n",
    "       - Set the content source for embedding to \"chunks\".\n",
    "\n",
    "3. Create an `ExtractionGraph` object from the YAML specification using `ExtractionGraph.from_yaml()`.\n",
    "\n",
    "4. Create the extraction graph on the Indexify client using `client.create_extraction_graph()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from indexify import ExtractionGraph\n",
    "\n",
    "extraction_graph_spec = \"\"\"\n",
    "name: 'transcribe'\n",
    "extraction_policies:\n",
    "   - extractor: 'tensorlake/asrdiarization'\n",
    "     name: 'sttextractor'\n",
    "     input_params:\n",
    "        batch_size: 24\n",
    "   - extractor: 'tensorlake/chunk-extractor'\n",
    "     name: 'chunker'\n",
    "     input_params:\n",
    "        chunk_size: 1000\n",
    "        overlap: 100\n",
    "     content_source: 'sttextractor'\n",
    "   - extractor: 'tensorlake/arctic'\n",
    "     name: 'embedder'\n",
    "     content_source: 'chunker'\n",
    "\"\"\"\n",
    "\n",
    "extraction_graph = ExtractionGraph.from_yaml(extraction_graph_spec)\n",
    "client.create_extraction_graph(extraction_graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upload any audio file to the Indexify Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "req = requests.get(\"https://raw.githubusercontent.com/tensorlakeai/indexify/main/docs/docs/files/interview.mp3\")\n",
    "\n",
    "with open('interview.mp3','wb') as f:\n",
    "    f.write(req.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26c06462ef9ce19b\n"
     ]
    }
   ],
   "source": [
    "content_id = client.upload_file(\"transcribe\", \"interview.mp3\")\n",
    "print(content_id)\n",
    "client.wait_for_extraction(content_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Performing RAG with OpenAI**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_context(question: str, index: str, top_k=1):\n",
    "    results = client.search_index(name=index, query=question, top_k=top_k)\n",
    "    context = \"\"\n",
    "    for result in results:\n",
    "        context = context + f\"content id: {result['content_id']} \\n\\n passage: {result['text']}\\n\"\n",
    "    return context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"content id: 6423bc4f19ad03cd \\n\\n passage: [{'speaker': 'SPEAKER_00', 'timestamp': (18.0, 22.0), 'text': ' So are you into fashion? Or are you kind of new to the fashion world?'}, {'speaker': 'SPEAKER_01', 'timestamp': (22.0, 24.0), 'text': ' I would consider myself new to the fashion world.'}, {'speaker': 'SPEAKER_01', 'timestamp': (24.0, 27.38), 'text': ' I, you know, this is like Mark said, fish out of water a little bit.'}, {'speaker': 'SPEAKER_01', 'timestamp': (27.38, 29.72), 'text': ' But I couldnt say no to the invitation.'}, {'speaker': 'SPEAKER_01', 'timestamp': (29.72, 32.24), 'text': ' I am opening my eyes about the world of fashion right now.'}]\\n\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"What does the guy has to say about his familiarity with the fashion world?\"\n",
    "context = get_context(question, \"transcribe.embedder.embedding\")\n",
    "context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_prompt(question, context):\n",
    "    return f\"Answer the question, based on the context.\\n question: {question} \\n context: {context}\"\n",
    "\n",
    "prompt = create_prompt(question, context)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instantiate the OpenAI Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "client_openai = OpenAI()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now ask any question related to the ingested audio file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the transcript, the man (SPEAKER_01) says that he is new to the fashion world and considers himself a 'fish out of water' in this context. However, he accepted the invitation despite his unfamiliarity with fashion. He also mentions that he is currently opening his eyes to the world of fashion, suggesting that this experience is exposing him to new insights about the industry.\n"
     ]
    }
   ],
   "source": [
    "chat_completion = client_openai.chat.completions.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": prompt,\n",
    "        }\n",
    "    ],\n",
    "    model=\"gpt-3.5-turbo\",\n",
    ")\n",
    "print(chat_completion.choices[0].message.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorlake",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **Setup**\n",
        "\n",
        "<div class=\"align-center\">\n",
        "  <a href=\"https://getindexify.ai/\"><img src=\"https://getindexify.ai/Indexify_Logo_Wordmark.svg\" width=\"145\"></a>\n",
        "  <a href=\"https://discord.com/invite/kF8UZACA7r\"><img src=\"https://raw.githubusercontent.com/rishiraj/random/main/Discord%20button.png\" width=\"145\"></a><br>\n",
        "  Join Discord if you need help + ⭐ <i>Star us on <a href=\"https://github.com/tensorlakeai/indexify\">Github</a></i> ⭐\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "%pip install indexify indexify-extractor-sdk indexify-langchain\n",
        "\n",
        "# Download Indexify Server\n",
        "!curl https://getindexify.ai | sh\n",
        "\n",
        "# Download Extractors\n",
        "!indexify-extractor download tensorlake/chunk-extractor\n",
        "!indexify-extractor download tensorlake/minilm-l6\n",
        "!indexify-extractor download tensorlake/marker"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "After installing the necessary libraries, download the server, and the extractors, you need to restart the runtime. Then, you have to run Indexify Server with the Extractors.\n",
        "\n",
        "Open 2 terminals and run the following commands:\n",
        "\n",
        "```bash\n",
        "# Terminal 1\n",
        "./indexify server -d\n",
        "\n",
        "# Terminal 2\n",
        "indexify-extractor join-server\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **Download the Rental PDF**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "import requests\n",
        "req = requests.get(\"https://www.timescar-rental.com/pdf/agreement/en_agreement_200401.pdf\")\n",
        "\n",
        "with open('en_agreement_200401.pdf','wb') as f:\n",
        "    f.write(req.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **Test the extractors**\n",
        "\n",
        "We will try MarkdownExtractor first. The MarkdownExtractor can extract all the values from text in one shot and passes it to the next chained extractors as a markdown formatted document which can be used for question answering."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from indexify_extractor_sdk import load_extractor, Content\n",
        "\n",
        "mdextractor, mdconfig_cls = load_extractor(\"indexify_extractors.markdown.markdown_extractor:MarkdownExtractor\")\n",
        "content = Content.from_file(\"en_agreement_200401.pdf\")\n",
        "\n",
        "md_result = mdextractor.extract(content)\n",
        "text_content = next(content.data.decode('utf-8') for content in md_result)\n",
        "text_content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sTIlKuPp6wxg"
      },
      "source": [
        "## **Create Extraction Graph**\n",
        "Instantiate the Indexify Client"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HZNysNl-631k"
      },
      "outputs": [],
      "source": [
        "from indexify import IndexifyClient\n",
        "client = IndexifyClient()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GQr1749x6_CW"
      },
      "source": [
        "First, create a policy to get texts and contents out of the Rental PDF."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "extraction_graph_spec = \"\"\"\n",
        "name: \"knowledgebase\"\n",
        "extraction_policies:\n",
        "  - extractor: \"tensorlake/markdown-extractor\"\n",
        "    name: \"md-extraction\"\n",
        "\n",
        "  - extractor: \"tensorlake/chunk-extractor\"\n",
        "    name: \"chunks\"\n",
        "    content_source: \"md-extraction\"\n",
        "    input_params:\n",
        "      chunk_size: 512\n",
        "      overlap: 150\n",
        "\n",
        "  - extractor: \"tensorlake/minilm-l6\"\n",
        "    name: \"get-embeddings\"\n",
        "    content_source: \"chunks\"\n",
        "\"\"\"\n",
        "extraction_graph = ExtractionGraph.from_yaml(extraction_graph_spec)\n",
        "client.create_extraction_graph(extraction_graph)  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZGqpkx3P7gsh"
      },
      "source": [
        "## **Upload PDF File**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ETideBqK8GGp"
      },
      "outputs": [],
      "source": [
        "cid = client.upload_file(\"knowledgebase\", path=\"en_agreement_200401.pdf\")\n",
        "client.wait_for_extraction(cid)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I2WDexIU8LFy"
      },
      "source": [
        "## **What is happening behind the scenes**\n",
        "\n",
        "Indexify is designed to seamlessly respond to ingestion events by assessing all existing policies and triggering the necessary extractors for extraction. Once the PDF extractor completes the process of extracting texts, bytes, and JSONs from the document, it automatically initiates the embedding extractor to chunk the content, extract embeddings, and populate an index.\n",
        "\n",
        "With Indexify, you have the ability to upload hundreds of Rental PDF files simultaneously, and the platform will efficiently handle the extraction and indexing of the contents without requiring manual intervention. To expedite the extraction process, you can deploy multiple instances of the extractors, and Indexify's built-in scheduler will transparently distribute the workload among them, ensuring optimal performance and efficiency."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B6SQ0xDt9a_9"
      },
      "source": [
        "## **Perform RAG**\n",
        "Initialize the Langchain Retriever."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2raD6aeB9Th1"
      },
      "outputs": [],
      "source": [
        "from indexify_langchain import IndexifyRetriever\n",
        "params = {\"name\": \"get-embeddings.embedding\", \"top_k\": 3}\n",
        "retriever = IndexifyRetriever(client=client, params=params)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K8Q1ulDM9u-e"
      },
      "source": [
        "Now create a chain to prompt OpenAI with data retrieved from Indexify to create a simple Q&A bot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8FUO8cLA9unF"
      },
      "outputs": [],
      "source": [
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "from langchain_openai import ChatOpenAI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yfgv3imm9ZPG"
      },
      "outputs": [],
      "source": [
        "template = \"\"\"Answer the question based only on the following context:\n",
        "{context}\n",
        "\n",
        "Question: {question}\n",
        "\"\"\"\n",
        "prompt = ChatPromptTemplate.from_template(template)\n",
        "\n",
        "model = ChatOpenAI()\n",
        "\n",
        "chain = (\n",
        "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
        "    | prompt\n",
        "    | model\n",
        "    | StrOutputParser()\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ckexWnEe-B3c"
      },
      "source": [
        "Now ask any question related to the ingested Rental PDF document"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cSc4uBLA-IEB"
      },
      "outputs": [],
      "source": [
        "chain.invoke(\"Who will be responsible for damages not compensated by the insurance?\")\n",
        "# The Renter and the Driver shall be responsible for damages not compensated for by the insurance benefit or compensation."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

---
title: 'Getting Started - Basic'
---

## Basic - Building a Wikipedia Information Retrieval System

![Getting Started Cover Image](https://github.com/user-attachments/assets/bce022db-3586-4cac-81ba-eb4426cdd90c)

In this guide, we'll walk you through creating an online ingestion pipeline for Wikipedia pages. This pipeline will demonstrate how to:

1. Extract structured information (Named Entity Recognition) from web pages using Large Language Models (LLMs)
2. Break down (chunk) the text, create embeddings, and store them in a vector database (LanceDB in this example)

By the end of this tutorial, you'll be able to:

1. Use advanced LLMs like GPT-4 or Mistral to answer questions based on indexed information (Retrieval-Augmented Generation or RAG)
2. Retrieve the Named Entities extracted from the text
3. Use a User Interface to visually debug your pipelines and inspect how pages are broken down into chunks

## Prerequisites

Before we begin, make sure you have:

1. Python 3.9 or higher installed
2. Basic knowledge of Python programming
3. Familiarity with command-line interfaces
4. An OpenAI API key (for using GPT models)

## Setup

You'll need three separate terminal windows open for this tutorial:

1. Terminal 1: For downloading and running the Indexify Server
2. Terminal 2: For running Indexify extractors (handling structured extraction, chunking, and embedding)
3. Terminal 3: For running Python scripts to load and query data from the Indexify server

We'll use the following notation to indicate which terminal to use:

```bash Terminal X Description of Command
command goes here
```

![Indexify Terminal](https://github.com/tensorlakeai/indexify-extractors/assets/44690292/c0185f07-5033-4e7c-9040-7854b996d430)

### Understanding Indexify Components

Here are components which you will touch while working through the example:

1. **Indexify Server**: The central coordinator and data ingestion API.
2. **Extractors**: Specialized workers designed to perform specific data processing tasks (e.g., embedding data, generating summaries, or extracting features from unstructured data).
3. **Extraction Graph**: A declarative YAML file that chains together extractors into a complex pipeline.

The directory structure of our project, will look like this 

```text Directory Structure
indexify-tutorial
│
├── venv                   # Virtual environment (created by python3 -m venv venv)
│
├── graph.yaml             # Extraction graph definition
├── setup.py               # Script to create the extraction graph
├── ingest.py              # Script to ingest Wikipedia data
├── query.py               # Script to query the indexed data
│
└── indexify               # Indexify server executable (downloaded by curl command)
```

## Step 1: Setting Up the Indexify Server

Let's start by downloading and running the Indexify server:

```bash Terminal 1 - Download Indexify Server
curl https://getindexify.ai | sh
./indexify server -d
```

This command creates two important endpoints:

1. Ingestion API: `http://localhost:8900`
2. User Interface: `http://localhost:8900/ui`

The Ingestion API is used for uploading content and retrieving data from indexes and SQL tables, while the User Interface provides a dashboard for visualizing extraction graphs, content, and indexes.

## Step 2: Creating a Virtual Environment

It's good practice to use a virtual environment for Python projects. Let's create one and install the necessary packages:

```bash Terminal 2 - Install Dependencies
python3 -m venv venv
source venv/bin/activate
pip3 install indexify-extractor-sdk indexify wikipedia openai langchain_community
```

## Step 3: Setting Up Indexify Extractors

The next step is to set up the extractors, which are essential for structured extraction from unstructured data across different modalities. For instance, in this example we use different extractors for parsing HTML and converting into text, chunking the text, and embedding it.

Extractors consume Content, which consists of raw bytes of unstructured data, and then produce a list of processed Content along with extracted features.

![Extractor Working](/images/Extractor_Transformation_Concept.png)

If you want to read and understand how to build a custom extractor for your own use case, go through the following section. However, if you want to use a built-in available extractor jump to the [next section](#using-available-extractors). 

### Using Custom Extractors

Custom Extractors are written by implementing a Python class that extends the `Extractor` abstractor class from the `indexify-extractor-sdk` package.

Here is an example Extrator, which does Named Entity Recognition on text data.

```python
class NerExtract(Extractor):
    name = 'yourorg/nerextractor'
    
    def extract(self, content: Content) -{'>'} List[Content]:
        """
        Extracts named entities from content.
        """
        output = []
        chunks = chunk_content(content)
        for chunk in chunks:
            entities = run_ner_model(chunk)
            metadata_chunk = Content(content_type='application/json', data=entities),
            output.append([metadata_chunk])
        return output
```

An extractor receives data in a `Content` object and transforms it into one or more `Content` objects, optionally adding `Embedding` objects during extraction. For example, you could split a PDF into multiple content pieces, each with its text and corresponding embedding or named entities detected in the text.

Indexify provides tools to test extractors locally, package and deploy them to production. For detailed instructions, [please see this page](apis/develop_extractors.md).

### Using Available Extractors

As mentioned before, for the purpose of this tutorial, we already have Extractors written, deployed and tested.
Set your OpenAI API key:

```bash Terminal 2 - Download Indexify Extractors
export OPENAI_API_KEY=your_api_key_here
```

Now, let's download three essential extractors:

```bash Terminal 2 - Download Indexify Extractors
source venv/bin/activate
indexify-extractor download tensorlake/openai
indexify-extractor download tensorlake/minilm-l6
indexify-extractor download tensorlake/chunk-extractor
indexify-extractor join-server
```

Now, let's start all available extractors:

```bash Terminal 2 - Starting Extractor Workers
indexify-extractor join-server
```

## Step 4: Defining Our Data Pipeline

We’ll define our data pipeline using a YAML file to process text documents by splitting them into chunks, extracting entities, and embedding the chunks in parallel. The following diagram outlines the Indexify end-to-end pipeline.

![Extraction Policy Graph](/images/extraction_graph_getting_started.jpg)

Let us create (or open) a file named `graph.yaml` with the following content:

```yaml graph.yaml
name: "wiki_extraction_pipeline"
extraction_policies:
  - extractor: "tensorlake/openai"
    name: "entity-extractor" 
    input_params:
      system_prompt: "Extract entities from text, and return the output in JSON format."
  - extractor: "tensorlake/chunk-extractor"
    name: "chunker"
    input_params:
      chunk_size: 1000
      overlap: 100
  - extractor: "tensorlake/minilm-l6"
    name: "wikiembedding"
    content_source: "chunker"
```

This YAML file defines three extraction policies:

1. `entity-extractor`: Extracts named entities from the text
2. `chunker`: Splits the text into smaller chunks
3. `wikiembedding`: Creates embeddings for the chunks

These are the three key extractors are utilized to process and analyze the input content from Wikipedia:

1. OpenAI Extractor(`tensorlake/openai`): Uses OpenAI’s LLMs for entity extraction from various input types (text, PDF, images). It can be customized with specific system and user prompts to tailor its output.

2. Chunk Extractor(`tensorlake/chunk-extractor`): Breaks down text into chunks, offering flexibility in chunk size and overlap.

3. MiniLM-L6 Extractor(`tensorlake/minilm-l6`): Generates embeddings of the text chunks for semantic search and retrieval.

These extractors work in concert to transform raw, unstructured input into processed, indexed, and easily retrievable information, forming the backbone of the Indexify pipeline for tasks such as entity recognition, text segmentation, and semantic embedding. You can learn more about different types of available extractors and their usage [here](https://docs.getindexify.ai/apis/extractors/).

## Step 5: Creating the Extraction Graph

Now, let's create a Python script to set up our extraction graph using the YAML file we just created.

Create a file named `setup.py` with the following content:

```python setup.py
from indexify import IndexifyClient, ExtractionGraph

client = IndexifyClient()

def create_extraction_graph():
    extraction_graph = ExtractionGraph.from_yaml_file("graph.yaml")
    client.create_extraction_graph(extraction_graph)

if __name__ == "__main__":
    create_extraction_graph()
```

Run this script to create the extraction graph:

```bash Terminal 3 - Create Extraction Graph
source venv/bin/activate
python3 ./setup.py
```

## Step 6: Loading Data

Now that we have our extraction graph set up, let's create (or open) a script to load the Wikipedia data into our pipeline.

Create a file named `ingest.py` with the following content:

```python ingest.py
from indexify import IndexifyClient, ExtractionGraph
from langchain_community.document_loaders import WikipediaLoader

client = IndexifyClient()

def load_data(player):
    docs = WikipediaLoader(query=player, load_max_docs=1).load()

    for doc in docs:
        client.add_documents("wiki_extraction_pipeline", doc.page_content)

if __name__ == "__main__":
    load_data("Kevin Durant")
    load_data("Stephen Curry")
```

Run this script to ingest data into Indexify:

```bash Terminal 3 - Ingest Data
source venv/bin/activate
python3 ./ingest.py
```

## Step 7: Querying Indexify

Now that we have data in our system, let's create a script to query Indexify and retrieve information.

You can query Indexify to - 

1. List ingested content by extraction graph. You can also list content per extraction policy.
2. Get extracted data from any of the extraction policies of an Extraction Graph.
3. Perform semantic search on vector indexes populated by embedding extractors.
4. Run SQL Queries on structured data(not in this tutorial).

```bash Terminal 3 - Run our RAG query
OPENAI_API_KEY=your_api_key_here python3 ./query.py
```

For now let us create a file named `query.py` with the following content:

```python query.py
from indexify import IndexifyClient
from openai import OpenAI

client = IndexifyClient()
client_openai = OpenAI()

# Get entities
ingested_content_list = client.list_content("wiki_extraction_pipeline")
content_id = ingested_content_list[0].id
entities = client.get_extracted_content(
    content_id, 
    "wiki_extraction_pipeline", 
    "entity-extractor")

# Get chunks
chunks = client.get_extracted_content(
    content_id, 
    "wiki_extraction_pipeline", 
    "chunker")

def query_database(question: str, index: str, top_k=3):
    retrieved_results = client.search_index(name=index, query=question, top_k=top_k)
    context = "\n-".join([item["text"] for item in retrieved_results])
    response = client_openai.chat.completions.create(
        messages=[
            {
                "role": "user",
                "content": f"Answer the question, based on the context.\n question: {question} \n context: {context}",
            },
        ],
        model="gpt-3.5-turbo",
    )
    return response.choices[0].message.content

if __name__ == "__main__":
    index_name = "wiki_extraction_pipeline.wikiembedding.embedding"
    indexes = client.indexes()
    print(f"Vector indexes present: {indexes}, querying index: {index_name}")
    print(
        query_database(
            "What accomplishments did Kevin durant achieve during his career?",
            "wiki_extraction_pipeline.wikiembedding.embedding",
            4,
        )
    )
```

Run this script to query the indexed data:

You should see a response summarizing Kevin Durant's career accomplishments based on the indexed Wikipedia data.

```text Output
During his career, Kevin Durant has achieved numerous accomplishments, including winning two NBA championships, an NBA Most Valuable Player Award, two Finals MVP Awards, two NBA All-Star Game Most Valuable Player Awards, four NBA scoring titles, the NBA Rookie of the Year Award, and being named to ten All-NBA teams (including six First Teams). He has also been selected as an NBA All-Star 14 times and was named to the NBA 75th Anniversary Team in 2021. Additionally, Durant has won three gold medals in the Olympics as a member of the U.S. men's national team and gold at the 2010 FIBA World Championship
```

## Conclusion

Congratulations, You've successfully set up an Indexify pipeline for ingesting, processing, and querying Wikipedia data. This guide has walked you through:

1. Setting up the Indexify server and extractors
2. Defining an extraction graph for processing Wikipedia pages
3. Ingesting data into the system
4. Querying the processed data using semantic search and GPT-3.5

Indexify's fault-tolerant design ensures reliability and scalability, making it suitable for mission-critical applications. You can now explore more advanced topics and integrations to further enhance your information retrieval and processing capabilities.

## Next Steps

To continue your journey with Indexify, consider exploring the following topics in order:

| Topics | Subtopics |
|--------|-----------|
| [Intermediate Use Case: Unstructured Data Extraction from a Tax PDF](https://docs.getindexify.ai/docs/getting-started-intermediate) | - Understanding the challenge of tax document processing \n  -  Setting up an Indexify pipeline for PDF extraction \n  -  Implementing extractors for key tax information \n  -  Querying and retrieving processed tax data |
| [Key Concepts of Indexify](https://docs.getindexify.ai/concepts/) | - Extractors \n  - Transformation \n  - Structured Data Extraction \n  - Embedding Extraction \n  - Combined Transformation, Embedding, and Metadata Extraction \n  -  Namespaces \n  -  Content \n  -  Extraction Graphs \n  -  Vector Index and Retrieval APIs \n  -  Structured Data Tables |
| [Architecture of Indexify](https://docs.getindexify.ai/architecture/) | - Indexify Server \n  - Coordinator \n  - Ingestion Server \n  -  Extractors \n  -  Deployment Layouts \n  - Local Mode \n  - Production Mode |
| [Building a Custom Extractor for Your Use Case](https://docs.getindexify.ai/apis/develop_extractors/) | - Understanding the Extractor SDK \n  -  Designing your extractor's functionality \n  -  Implementing the extractor class \n  -  Testing and debugging your custom extractor \n  -  Integrating the custom extractor into your Indexify pipeline |
| [Examples and Use Cases](https://docs.getindexify.ai/examples/index/) | - Document processing and analysis \n  -  Image and video content extraction \n  -  Audio transcription and analysis \n  -  Multi-modal data processing \n  -  Large-scale data ingestion and retrieval systems |

Each section builds upon the previous ones, providing a logical progression from practical application to deeper technical understanding and finally to customization and real-world examples.

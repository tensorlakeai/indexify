# Fast Extraction Pipelines and Retrieval for AI Applications at Any Scale

![Indexify High Level](images/Indexify_KAT.gif)

Indexify is data framework for building LLM Applications that derives knowledge from enterprise or consumer data to make decisions or answer questions. It shines in use-cases where ground truth sources of infromation changes over time. Most data sources in the real world are unstructured and orginate from PDFs, clicks on websites, emails, text messages or videos. Indexify brings information from unstructured data sources to LLMs continously for production applications.

It provides the following primitives - 

1. **Real Time Data Pipelines** - Declarative data transformation and extraction graphs that execute whenever new data is ingested.
2. **Extractor SDK** - SDK to write embedding and un-structured data extraction algorithms that can be used by real-time pipelines.
3. **Storage Interface** - Extracted data is automatically stored in vector stores, structured data stores and blob stores.
4. **Retreival API** - Exposes data from vector stores and structured stores using Semantic Search APIs and SQL. 


## Why Use Indexify 
Building a data-intensive product with LLMs often involves -

1. Ingesting new data, extracting structured infromation, or embedding and writing them to storage.
2. Setting up fault tolerant pipelines to do the ingestion-extraction process continously as new data is generated by humans or business processes.
3. Running compute intensive models for extraction efficiently in pipelines.
4. Serving fresh data by searching vector indexes adn structured stores to LLMs for making accurate decisions.

While there are many data frameworks for unstructured data, they are mostly optimized for prototyping applications locally. Reliable data infrastructure for production use-cases are designed to be distributed on many machines to allow scale outs, fault tolerant to hardware or software crashes, have predictable latencies and throughput, and observable to help with troubleshooting.

Indexify runs locally without **any** dependencies, making it easy to build applications and test and iterate locally. It does so without sacrificing the properties that makes data systems shine in production environments. Applications built with Indexify can run on laptops can run un-changed in production. Indexify can auto-scale, distributed and fault tolerant and fully observable with predictable latencies and throughput. 

## Start Using Indexify

Dive into [Getting Started](getting_started.md) to learn how to use Indexify.

If you would like to learn some common usecases - 

1. Learn how to build production grade [RAG Applications](usecases/rag.md)
2. Extract [PDF](usecases/pdf_extraction.md), [Videos](usecases/video_rag.md) and [Audio](usecases/audio_extraction.md) to extract embedding and [structured data](usecases/image_retrieval.md).

## Features

* Makes Unstructured Data **Queryable** with **SQL** and **Semantic Search**
* **Real Time** Extraction Engine to keep indexes **automatically** updated as new data is ingested.
* Create **Extraction Graph** to create multi-step workflows for **data transformation**, **embedding** and **structured extraction**.
* **Incremental Extraction** and **Selective Deletion** when content is deleted or updated.
* **Extractor SDK** allows adding new extraction capabilities, and many readily avaialble extractors for **PDF**, **Image** and **Video** indexing and extraction.
* **Multi-Tenant** from the ground up, **Namespaces** to isolate sensistive data.
* Works with **any LLM Framework** including **Langchain**, **DSPy**, etc.
* Runs on your laptop during **prototyping** and also scales to **1000s of machines** on the cloud.
* Works with many **Blob Stores**, **Vector Stores** and **Structured Databases**
* We have even **Open Sourced Automation** to deploy to Kubernetes in production.


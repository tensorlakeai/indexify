#[allow(non_camel_case_types)] // The autogenerated code uses snake_case types in some cases
pub mod executor_api_pb {
    tonic::include_proto!("executor_api_pb");
}

use std::{collections::HashMap, pin::Pin, sync::Arc};

use data_model::{
    ExecutorId,
    ExecutorMetadata,
    ExecutorMetadataBuilder,
    FunctionExecutor,
    FunctionExecutorStatus,
    FunctionURI,
    GpuResources,
    GraphVersion,
    HostResources,
};
use executor_api_pb::{
    executor_api_server::ExecutorApi,
    AllowedFunction,
    DesiredExecutorState,
    ExecutorState,
    FunctionExecutorDescription,
    GetDesiredExecutorStatesRequest,
    GpuModel,
    ReportExecutorStateRequest,
    ReportExecutorStateResponse,
};
use state_store::IndexifyState;
use tokio::sync::mpsc;
use tokio_stream::{wrappers::ReceiverStream, Stream, StreamExt};
use tonic::{Request, Response, Status};
use tracing::info;

use crate::executors::ExecutorManager;

impl TryFrom<AllowedFunction> for FunctionURI {
    type Error = anyhow::Error;

    fn try_from(allowed_function: AllowedFunction) -> Result<Self, Self::Error> {
        let namespace = allowed_function
            .namespace
            .ok_or(anyhow::anyhow!("namespace is required"))?;
        let compute_graph_name = allowed_function
            .graph_name
            .ok_or(anyhow::anyhow!("compute_graph_name is required"))?;
        let compute_fn_name = allowed_function
            .function_name
            .ok_or(anyhow::anyhow!("compute_fn_name is required"))?;
        let version = allowed_function.graph_version.map(|v| GraphVersion(v));
        Ok(FunctionURI {
            namespace,
            compute_graph_name,
            compute_fn_name,
            version,
        })
    }
}

impl From<GpuModel> for String {
    fn from(gpu_model: GpuModel) -> Self {
        match gpu_model {
            GpuModel::NvidiaTeslaT416gb => "T4".to_string(),
            GpuModel::NvidiaTeslaV10016gb => "V100".to_string(),
            GpuModel::NvidiaA1024gb => "A10".to_string(),
            GpuModel::NvidiaA600048gb => "A6000".to_string(),
            GpuModel::NvidiaA100Sxm440gb => "A100".to_string(),
            GpuModel::NvidiaA100Sxm480gb => "A100".to_string(),
            GpuModel::NvidiaA100Pci40gb => "A100".to_string(),
            GpuModel::NvidiaH100Sxm580gb => "H100".to_string(),
            GpuModel::NvidiaH100Pci80gb => "H100".to_string(),
            GpuModel::NvidiaRtx600024gb => "RTX6000".to_string(),
            GpuModel::Unknown => "Unknown".to_string(),
        }
    }
}

impl TryFrom<ExecutorState> for ExecutorMetadata {
    type Error = anyhow::Error;

    fn try_from(executor_state: ExecutorState) -> Result<Self, Self::Error> {
        let mut executor_metadata = ExecutorMetadataBuilder::default();
        if let Some(executor_id) = executor_state.executor_id {
            executor_metadata.id(ExecutorId::new(executor_id));
        }
        if let Some(flavor_version) = executor_state.flavor_version {
            executor_metadata.executor_version(flavor_version);
        }
        let mut allowed_functions = Vec::new();
        for function in executor_state.allowed_functions {
            allowed_functions.push(FunctionURI::try_from(function)?);
        }
        if !allowed_functions.is_empty() {
            executor_metadata.function_allowlist(Some(allowed_functions));
        }
        if let Some(addr) = executor_state.hostname {
            executor_metadata.addr(addr);
        }
        let mut labels = HashMap::new();
        for (key, value) in executor_state.labels {
            labels.insert(key, serde_json::Value::String(value));
        }
        if !labels.is_empty() {
            executor_metadata.labels(labels);
        }
        let mut function_executors = HashMap::new();
        for function_executor in executor_state.function_executor_states {
            let function_executor_description = function_executor
                .description
                .ok_or(anyhow::anyhow!("description is required"))?;
            let mut function_executor = FunctionExecutor::try_from(function_executor_description)?;
            function_executor.status = FunctionExecutorStatus::try_from(function_executor.status)?;
            function_executors.insert(function_executor.id.clone(), function_executor);
        }
        if let Some(host_resources) = executor_state.free_resources {
            let cpu = host_resources
                .cpu_count
                .ok_or(anyhow::anyhow!("cpu_count is required"))?;
            let memory = host_resources
                .memory_bytes
                .ok_or(anyhow::anyhow!("memory_bytes is required"))?;
            let disk = host_resources
                .disk_bytes
                .ok_or(anyhow::anyhow!("disk_bytes is required"))?;
            let gpu = host_resources.gpu.map(|g| GpuResources {
                count: g.count(),
                model: g.model().into(),
            });
            executor_metadata.host_resources(HostResources {
                cpu_count: cpu,
                memory_bytes: memory,
                disk_bytes: disk,
                gpu,
            });
        }
        Ok(executor_metadata.build()?)
    }
}

impl TryFrom<FunctionExecutorDescription> for FunctionExecutor {
    type Error = anyhow::Error;

    fn try_from(
        function_executor_description: FunctionExecutorDescription,
    ) -> Result<Self, Self::Error> {
        let id = function_executor_description
            .id
            .ok_or(anyhow::anyhow!("id is required"))?;
        let namespace = function_executor_description
            .namespace
            .ok_or(anyhow::anyhow!("namespace is required"))?;
        let compute_graph_name = function_executor_description
            .graph_name
            .ok_or(anyhow::anyhow!("compute_graph_name is required"))?;
        let compute_fn_name = function_executor_description
            .function_name
            .ok_or(anyhow::anyhow!("compute_fn_name is required"))?;
        let version = function_executor_description
            .graph_version
            .ok_or(anyhow::anyhow!("version is required"))?;
        Ok(FunctionExecutor {
            id,
            namespace,
            compute_graph_name,
            compute_fn_name,
            version: GraphVersion(version),
            status: FunctionExecutorStatus::Unknown,
        })
    }
}

pub struct ExecutorAPIService {
    _indexify_state: Arc<IndexifyState>,
    executor_manager: Arc<ExecutorManager>,
}

impl ExecutorAPIService {
    pub fn new(indexify_state: Arc<IndexifyState>, executor_manager: Arc<ExecutorManager>) -> Self {
        Self {
            _indexify_state: indexify_state,
            executor_manager,
        }
    }
}

#[tonic::async_trait]
impl ExecutorApi for ExecutorAPIService {
    #[allow(non_camel_case_types)] // The autogenerated code in the trait uses snake_case types in some cases
    type get_desired_executor_statesStream =
        Pin<Box<dyn Stream<Item = Result<DesiredExecutorState, Status>> + Send>>;

    async fn report_executor_state(
        &self,
        request: Request<ReportExecutorStateRequest>,
    ) -> Result<Response<ReportExecutorStateResponse>, Status> {
        let executor_state = request
            .get_ref()
            .executor_state
            .clone()
            .ok_or(Status::invalid_argument("executor_state is required"))?;
        info!(
            "Got report_executor_state request from Executor with ID {}",
            executor_state.executor_id()
        );
        // Comment out not finished functionality.
        // let executor_metadata =
        ExecutorMetadata::try_from(executor_state)
            .map_err(|e| Status::invalid_argument(e.to_string()))?;
        // self.executor_manager
        //     .heartbeat(executor_metadata)
        //     .await
        //     .map_err(|e| Status::internal(e.to_string()))?;
        Ok(Response::new(ReportExecutorStateResponse {}))
    }

    async fn get_desired_executor_states(
        &self,
        request: Request<GetDesiredExecutorStatesRequest>,
    ) -> Result<Response<Self::get_desired_executor_statesStream>, Status> {
        info!(
            "Got get_desired_executor_states request from Executor with ID {}",
            request.get_ref().executor_id()
        );

        // Based on https://github.com/hyperium/tonic/blob/72b0fd59442d71804d4104e313ef6f140ab8f6d1/examples/src/streaming/server.rs#L46
        // creating infinite stream with fake message
        let repeat = std::iter::repeat(DesiredExecutorState {
            function_executors: vec![],
            task_allocations: vec![],
            clock: Some(3),
        });
        let mut stream = Box::pin(tokio_stream::iter(repeat));

        // spawn and channel are required if you want handle "disconnect" functionality
        // the `out_stream` will not be polled after client disconnect
        let (tx, rx) = mpsc::channel(128);
        tokio::spawn(async move {
            while let Some(item) = stream.next().await {
                match tx.send(Result::<_, Status>::Ok(item)).await {
                    Ok(_) => {
                        // item (server response) was queued to be send to
                        // client
                    }
                    Err(_item) => {
                        // output_stream was build from rx and both are dropped
                        break;
                    }
                }
            }
            info!("get_desired_executor_states stream finished, client disconnected");
        });

        let output_stream = ReceiverStream::new(rx);
        Ok(Response::new(
            Box::pin(output_stream) as Self::get_desired_executor_statesStream
        ))
    }
}

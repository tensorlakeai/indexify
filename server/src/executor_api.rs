#[allow(non_camel_case_types)] // The autogenerated code uses snake_case types in some cases
pub mod executor_api_pb {
    tonic::include_proto!("executor_api_pb");
}

use std::{collections::HashMap, pin::Pin, sync::Arc};

use data_model::{
    DataPayload,
    ExecutorId,
    ExecutorMetadata,
    ExecutorMetadataBuilder,
    FunctionExecutor,
    FunctionExecutorId,
    FunctionExecutorStatus,
    FunctionURI,
    GraphVersion,
    HostResources,
    NodeOutputBuilder,
    OutputPayload,
    TaskDiagnostics,
    TaskOutcome,
    TaskOutputsIngestionStatus,
    TaskStatus,
};
use executor_api_pb::{
    executor_api_server::ExecutorApi,
    AllowedFunction,
    DataPayloadEncoding,
    DesiredExecutorState,
    ExecutorState,
    ExecutorStatus,
    FunctionExecutorDescription,
    GetDesiredExecutorStatesRequest,
    OutputEncoding,
    ReportExecutorStateRequest,
    ReportExecutorStateResponse,
    ReportTaskOutcomeRequest,
    ReportTaskOutcomeResponse,
};
use metrics::api_io_stats;
use state_store::{
    requests::{IngestTaskOutputsRequest, RequestPayload, StateMachineUpdateRequest},
    IndexifyState,
};
use tokio::sync::mpsc;
use tokio_stream::{wrappers::ReceiverStream, Stream, StreamExt};
use tonic::{Request, Response, Status};
use tracing::{debug, error, info, warn};

use crate::executors::ExecutorManager;

impl TryFrom<AllowedFunction> for FunctionURI {
    type Error = anyhow::Error;

    fn try_from(allowed_function: AllowedFunction) -> Result<Self, Self::Error> {
        let namespace = allowed_function
            .namespace
            .ok_or(anyhow::anyhow!("namespace is required"))?;
        let compute_graph_name = allowed_function
            .graph_name
            .ok_or(anyhow::anyhow!("compute_graph_name is required"))?;
        let compute_fn_name = allowed_function
            .function_name
            .ok_or(anyhow::anyhow!("compute_fn_name is required"))?;
        let version = allowed_function.graph_version.map(|v| GraphVersion(v));
        Ok(FunctionURI {
            namespace,
            compute_graph_name,
            compute_fn_name,
            version,
        })
    }
}

impl From<ExecutorStatus> for data_model::ExecutorState {
    fn from(status: ExecutorStatus) -> Self {
        match status {
            ExecutorStatus::StartingUp => data_model::ExecutorState::StartingUp,
            ExecutorStatus::Running => data_model::ExecutorState::Running,
            ExecutorStatus::Drained => data_model::ExecutorState::Drained,
            ExecutorStatus::Stopping => data_model::ExecutorState::Stopping,
            ExecutorStatus::Stopped => data_model::ExecutorState::Stopped,
            ExecutorStatus::Unknown => data_model::ExecutorState::Unknown,
        }
    }
}

impl TryFrom<executor_api_pb::GpuResources> for data_model::GpuResources {
    type Error = anyhow::Error;

    fn try_from(gpu_resources: executor_api_pb::GpuResources) -> Result<Self, Self::Error> {
        if gpu_resources.count() == 0 {
            return Err(anyhow::anyhow!("proto gpu_resources.count is 0"));
        }
        let str_model = match gpu_resources.model() {
            executor_api_pb::GpuModel::Unknown => {
                Err(anyhow::anyhow!("proto gpu_resources.model is unknown"))
            }
            executor_api_pb::GpuModel::NvidiaA10040gb => Ok(data_model::GPU_MODEL_NVIDIA_A100_40GB),
            executor_api_pb::GpuModel::NvidiaA10080gb => Ok(data_model::GPU_MODEL_NVIDIA_A100_80GB),
            executor_api_pb::GpuModel::NvidiaH10080gb => Ok(data_model::GPU_MODEL_NVIDIA_H100_80GB),
            executor_api_pb::GpuModel::NvidiaTeslaT4 => Ok(data_model::GPU_MODEL_NVIDIA_TESLA_T4),
        }?;
        Ok(data_model::GpuResources {
            count: gpu_resources.count(),
            model: str_model.into(),
        })
    }
}

impl TryFrom<ExecutorState> for ExecutorMetadata {
    type Error = anyhow::Error;

    fn try_from(executor_state: ExecutorState) -> Result<Self, Self::Error> {
        let mut executor_metadata = ExecutorMetadataBuilder::default();
        let executor_id = executor_state
            .executor_id
            .clone()
            .map(ExecutorId::new)
            .ok_or(anyhow::anyhow!("executor_id is required"))?;
        executor_metadata.id(executor_id.clone());
        executor_metadata.state(executor_state.status().into());
        executor_metadata.development_mode(
            executor_state
                .development_mode
                .ok_or(anyhow::anyhow!("development_mode is required"))?,
        );
        if let Some(state_hash) = executor_state.state_hash.clone() {
            executor_metadata.state_hash(state_hash);
        }
        // FIXME: ignoring Executor flavor for now.
        if let Some(executor_version) = executor_state.version {
            executor_metadata.executor_version(executor_version);
        }
        let mut allowed_functions = Vec::new();
        for function in executor_state.allowed_functions {
            allowed_functions.push(FunctionURI::try_from(function)?);
        }
        if allowed_functions.is_empty() {
            executor_metadata.function_allowlist(None);
        } else {
            executor_metadata.function_allowlist(Some(allowed_functions));
        }
        if let Some(addr) = executor_state.hostname {
            executor_metadata.addr(addr);
        }
        let mut labels = HashMap::new();
        for (key, value) in executor_state.labels {
            labels.insert(key, serde_json::Value::String(value));
        }
        executor_metadata.labels(labels);
        let mut function_executors = HashMap::new();
        for function_executor in executor_state.function_executor_states {
            let function_executor_description = function_executor
                .description
                .ok_or(anyhow::anyhow!("description is required"))?;
            let mut function_executor = FunctionExecutor::try_from(WithExecutorId::new(
                executor_id.clone(),
                function_executor_description,
            ))?;
            function_executor.status = FunctionExecutorStatus::try_from(function_executor.status)?;
            function_executors.insert(function_executor.id.clone(), function_executor);
        }
        executor_metadata.function_executors(function_executors);
        if let Some(host_resources) = executor_state.free_resources {
            let cpu = host_resources
                .cpu_count
                .ok_or(anyhow::anyhow!("cpu_count is required"))?;
            let memory = host_resources
                .memory_bytes
                .ok_or(anyhow::anyhow!("memory_bytes is required"))?;
            let disk = host_resources
                .disk_bytes
                .ok_or(anyhow::anyhow!("disk_bytes is required"))?;
            // Ignore errors during conversion as they are expected e.g. if Executor GPU
            // model is unknown.
            let gpu = match host_resources.gpu {
                Some(gpu_resources) => gpu_resources.try_into().ok(),
                None => None,
            };
            executor_metadata.host_resources(HostResources {
                cpu_count: cpu,
                memory_bytes: memory,
                disk_bytes: disk,
                gpu,
            });
        }
        Ok(executor_metadata.build()?)
    }
}

struct WithExecutorId<T> {
    executor_id: ExecutorId,
    inner: T,
}

impl<T> WithExecutorId<T> {
    fn new(executor_id: ExecutorId, inner: T) -> Self {
        Self { executor_id, inner }
    }
}

impl TryFrom<WithExecutorId<FunctionExecutorDescription>> for FunctionExecutor {
    type Error = anyhow::Error;

    fn try_from(from: WithExecutorId<FunctionExecutorDescription>) -> Result<Self, Self::Error> {
        let function_executor_description = from.inner;
        let id = function_executor_description
            .id
            .map(|id| FunctionExecutorId::new(id))
            .ok_or(anyhow::anyhow!("id is required"))?;
        let namespace = function_executor_description
            .namespace
            .ok_or(anyhow::anyhow!("namespace is required"))?;
        let compute_graph_name = function_executor_description
            .graph_name
            .ok_or(anyhow::anyhow!("compute_graph_name is required"))?;
        let compute_fn_name = function_executor_description
            .function_name
            .ok_or(anyhow::anyhow!("compute_fn_name is required"))?;
        let version = function_executor_description
            .graph_version
            .map(GraphVersion)
            .ok_or(anyhow::anyhow!("version is required"))?;

        Ok(FunctionExecutor {
            id,
            executor_id: from.executor_id,
            namespace,
            compute_graph_name,
            compute_fn_name,
            version,
            status: FunctionExecutorStatus::Unknown,
        })
    }
}

pub struct ExecutorAPIService {
    indexify_state: Arc<IndexifyState>,
    executor_manager: Arc<ExecutorManager>,
    api_metrics: Arc<api_io_stats::Metrics>,
    blob_storage: Arc<blob_store::BlobStorage>,
}

impl ExecutorAPIService {
    pub fn new(
        indexify_state: Arc<IndexifyState>,
        executor_manager: Arc<ExecutorManager>,
        api_metrics: Arc<api_io_stats::Metrics>,
        blob_storage: Arc<blob_store::BlobStorage>,
    ) -> Self {
        Self {
            indexify_state,
            executor_manager,
            api_metrics,
            blob_storage,
        }
    }
}

#[tonic::async_trait]
impl ExecutorApi for ExecutorAPIService {
    #[allow(non_camel_case_types)] // The autogenerated code in the trait uses snake_case types in some cases
    type get_desired_executor_statesStream =
        Pin<Box<dyn Stream<Item = Result<DesiredExecutorState, Status>> + Send>>;

    async fn report_executor_state(
        &self,
        request: Request<ReportExecutorStateRequest>,
    ) -> Result<Response<ReportExecutorStateResponse>, Status> {
        let executor_state = request
            .get_ref()
            .executor_state
            .clone()
            .ok_or(Status::invalid_argument("executor_state is required"))?;
        debug!(
            "Got report_executor_state request from Executor with ID {}",
            executor_state.executor_id()
        );
        let executor_metadata = ExecutorMetadata::try_from(executor_state)
            .map_err(|e| Status::invalid_argument(e.to_string()))?;
        self.executor_manager
            .heartbeat(executor_metadata)
            .await
            .map_err(|e| Status::internal(e.to_string()))?;
        Ok(Response::new(ReportExecutorStateResponse {}))
    }

    async fn get_desired_executor_states(
        &self,
        request: Request<GetDesiredExecutorStatesRequest>,
    ) -> Result<Response<Self::get_desired_executor_statesStream>, Status> {
        info!(
            "Got get_desired_executor_states request from Executor with ID {}",
            request.get_ref().executor_id()
        );

        // Based on https://github.com/hyperium/tonic/blob/72b0fd59442d71804d4104e313ef6f140ab8f6d1/examples/src/streaming/server.rs#L46
        // creating infinite stream with fake message
        let repeat = std::iter::repeat(DesiredExecutorState {
            function_executors: vec![],
            task_allocations: vec![],
            clock: Some(3),
        });
        let mut stream = Box::pin(tokio_stream::iter(repeat));

        // spawn and channel are required if you want handle "disconnect" functionality
        // the `out_stream` will not be polled after client disconnect
        let (tx, rx) = mpsc::channel(128);
        tokio::spawn(async move {
            while let Some(item) = stream.next().await {
                match tx.send(Result::<_, Status>::Ok(item)).await {
                    Ok(_) => {
                        // item (server response) was queued to be send to
                        // client
                    }
                    Err(_item) => {
                        // output_stream was build from rx and both are dropped
                        break;
                    }
                }
            }
            info!("get_desired_executor_states stream finished, client disconnected");
        });

        let output_stream = ReceiverStream::new(rx);
        Ok(Response::new(
            Box::pin(output_stream) as Self::get_desired_executor_statesStream
        ))
    }

    async fn report_task_outcome(
        &self,
        request: Request<ReportTaskOutcomeRequest>,
    ) -> Result<Response<ReportTaskOutcomeResponse>, Status> {
        self.api_metrics
            .fn_outputs
            .add(request.get_ref().fn_outputs.len() as u64, &[]);

        let task_id = request
            .get_ref()
            .task_id
            .clone()
            .ok_or(Status::invalid_argument("task_id is required"))?;

        let task_outcome =
            executor_api_pb::TaskOutcome::try_from(request.get_ref().outcome.unwrap_or(0))
                .map_err(|e| Status::invalid_argument(e.to_string()))?;

        let executor_id = request
            .get_ref()
            .executor_id
            .clone()
            .ok_or(Status::invalid_argument("executor_id is required"))?;
        let namespace = request
            .get_ref()
            .namespace
            .clone()
            .ok_or(Status::invalid_argument("namespace is required"))?;
        let compute_graph = request
            .get_ref()
            .graph_name
            .clone()
            .ok_or(Status::invalid_argument("compute_graph is required"))?;
        let compute_fn = request
            .get_ref()
            .function_name
            .clone()
            .ok_or(Status::invalid_argument("compute_fn is required"))?;
        let invocation_id = request
            .get_ref()
            .graph_invocation_id
            .clone()
            .ok_or(Status::invalid_argument("graph_invocation_id is required"))?;
        let task = self
            .indexify_state
            .reader()
            .get_task(
                &namespace,
                &compute_graph,
                &invocation_id,
                &compute_fn,
                &task_id,
            )
            .map_err(|e| Status::internal(e.to_string()))?;
        if task.is_none() {
            warn!("Task not found for task_id: {}", task_id);
            return Ok(Response::new(ReportTaskOutcomeResponse {}));
        }
        let mut task = task.unwrap();
        match task_outcome {
            executor_api_pb::TaskOutcome::Success => {
                task.outcome = TaskOutcome::Success;
            }
            executor_api_pb::TaskOutcome::Failure => {
                task.outcome = TaskOutcome::Failure;
            }
            executor_api_pb::TaskOutcome::Unknown => {
                task.outcome = TaskOutcome::Unknown;
            }
        }
        task.output_status = TaskOutputsIngestionStatus::Ingested;
        task.status = TaskStatus::Completed;

        let mut node_outputs = Vec::new();
        for output in request.get_ref().fn_outputs.clone() {
            let path = output
                .path
                .or(output.uri)
                .ok_or(Status::invalid_argument("path or uri is required"))?;

            let path = blob_store_url_to_path(
                &path,
                &self.blob_storage.get_url_scheme(),
                &self.blob_storage.get_url(),
            );
            let size = output
                .size
                .ok_or(Status::invalid_argument("size is required"))?;
            let sha256_hash = output
                .sha256_hash
                .ok_or(Status::invalid_argument("sha256_hash is required"))?;
            let data_payload = DataPayload {
                path,
                size,
                sha256_hash,
            };
            let encoding_str = match output.encoding {
                Some(value) => {
                    let output_encoding = DataPayloadEncoding::try_from(value)
                        .map_err(|e| Status::invalid_argument(e.to_string()))?;
                    match output_encoding {
                        DataPayloadEncoding::Utf8Json => Ok("application/json"),
                        DataPayloadEncoding::BinaryPickle => Ok("application/octet-stream"),
                        DataPayloadEncoding::Utf8Text => Ok("text/plain"),
                        DataPayloadEncoding::Unknown => {
                            Err(Status::invalid_argument("unknown data payload encoding"))
                        }
                    }
                }
                // Fallback to the deprecated request encoding if not set
                None => match request.get_ref().output_encoding {
                    Some(value) => {
                        let output_encoding = OutputEncoding::try_from(value)
                            .map_err(|e| Status::invalid_argument(e.to_string()))?;
                        match output_encoding {
                            OutputEncoding::Json => Ok("application/json"),
                            OutputEncoding::Pickle => Ok("application/octet-stream"),
                            OutputEncoding::Binary => Ok("application/octet-stream"),
                            OutputEncoding::Unknown => {
                                Err(Status::invalid_argument("unknown request output encoding"))
                            }
                        }
                    }
                    None => Err(Status::invalid_argument(
                        "data payload encoding or request output encoding is required",
                    )),
                },
            }?;

            let node_output = NodeOutputBuilder::default()
                .namespace(namespace.to_string())
                .compute_graph_name(compute_graph.to_string())
                .invocation_id(invocation_id.to_string())
                .compute_fn_name(compute_fn.to_string())
                .payload(OutputPayload::Fn(data_payload))
                .encoding(encoding_str.to_string())
                .build()
                .map_err(|e| Status::internal(e.to_string()))?;
            node_outputs.push(node_output);
        }

        if request.get_ref().next_functions.len() > 0 {
            let node_output = NodeOutputBuilder::default()
                .namespace(namespace.to_string())
                .compute_graph_name(compute_graph.to_string())
                .invocation_id(invocation_id.to_string())
                .compute_fn_name(compute_fn.to_string())
                .payload(OutputPayload::Router(data_model::RouterOutput {
                    edges: request.get_ref().next_functions.clone(),
                }))
                .build()
                .map_err(|e| Status::internal(e.to_string()))?;
            node_outputs.push(node_output);
        }
        let task_diagnostic = TaskDiagnostics {
            stdout: prepare_data_payload(
                request.get_ref().stdout.clone(),
                &self.blob_storage.get_url_scheme(),
                &self.blob_storage.get_url(),
            ),
            stderr: prepare_data_payload(
                request.get_ref().stderr.clone(),
                &self.blob_storage.get_url_scheme(),
                &self.blob_storage.get_url(),
            ),
        };
        task.diagnostics = Some(task_diagnostic.clone());
        let request = RequestPayload::IngestTaskOutputs(IngestTaskOutputsRequest {
            namespace: namespace.to_string(),
            compute_graph: compute_graph.to_string(),
            compute_fn: compute_fn.to_string(),
            invocation_id: invocation_id.to_string(),
            task: task.clone(),
            node_outputs,
            executor_id: ExecutorId::new(executor_id.clone()),
        });

        let sm_req = StateMachineUpdateRequest {
            payload: request,
            processed_state_changes: vec![],
        };

        self.indexify_state
            .write(sm_req)
            .await
            .map_err(|e| Status::internal(e.to_string()))?;
        Ok(Response::new(ReportTaskOutcomeResponse {}))
    }
}

fn prepare_data_payload(
    msg: Option<executor_api_pb::DataPayload>,
    blob_store_url_scheme: &str,
    blob_store_url: &str,
) -> Option<data_model::DataPayload> {
    if msg.is_none() {
        return None;
    }
    let msg = msg.unwrap();
    if msg.uri.is_none() && msg.path.is_none() {
        return None;
    }
    if msg.size.as_ref().is_none() {
        return None;
    }
    if msg.sha256_hash.as_ref().is_none() {
        return None;
    }

    // Fallback to deprecated path if uri is not set.
    let path = msg.uri.or(msg.path).unwrap();
    Some(data_model::DataPayload {
        path: blob_store_url_to_path(&path, blob_store_url_scheme, blob_store_url),
        size: msg.size.unwrap(),
        sha256_hash: msg.sha256_hash.unwrap(),
    })
}

pub fn blob_store_path_to_url(
    path: &str,
    blob_store_url_scheme: &str,
    blob_store_url: &str,
) -> String {
    if blob_store_url_scheme == "file" {
        // Local file blob store implementation is always using absolute paths without
        // "/"" prefix. The paths are not relative to the configure blob_store_url path.
        return format!("{}:///{}", blob_store_url_scheme, path);
    } else if blob_store_url_scheme == "s3" {
        // S3 blob store implementation uses paths relative to its bucket from
        // blob_store_url.
        return format!(
            "{}://{}/{}",
            blob_store_url_scheme,
            bucket_name_from_s3_blob_store_url(blob_store_url),
            path
        );
    } else {
        return format!("not supported blob store scheme: {}", blob_store_url_scheme);
    }
}

pub fn blob_store_url_to_path(
    url: &str,
    blob_store_url_scheme: &str,
    blob_store_url: &str,
) -> String {
    if blob_store_url_scheme == "file" {
        // Local file blob store implementation is always using absolute paths without
        // "/"" prefix. The paths are not relative to the configure blob_store_url path.
        return url
            .strip_prefix(&format!("{}:///", blob_store_url_scheme).to_string())
            // The url doesn't include blob_store_scheme if this payload was uploaded to server
            // instead of directly to blob storage.
            .unwrap_or(url)
            .to_string();
    } else if blob_store_url_scheme == "s3" {
        // S3 blob store implementation uses paths relative to its bucket from
        // blob_store_url.
        return url
            .strip_prefix(
                &format!(
                    "{}://{}/",
                    blob_store_url_scheme,
                    bucket_name_from_s3_blob_store_url(blob_store_url)
                )
                .to_string(),
            )
            // The url doesn't include blob_store_url if this payload was uploaded to server instead
            // of directly to blob storage.
            .unwrap_or(url)
            .to_string();
    } else {
        return format!("not supported blob store scheme: {}", blob_store_url_scheme);
    }
}

fn bucket_name_from_s3_blob_store_url(blob_store_url: &str) -> String {
    match url::Url::parse(blob_store_url) {
        Ok(url) => match url.host_str() {
            Some(bucket) => bucket.into(),
            None => {
                error!("Didn't find bucket name in S3 url: {}", blob_store_url);
                return String::new();
            }
        },
        Err(e) => {
            error!(
                "Failed to parse blob_store_url: {}. Error: {}",
                blob_store_url, e
            );
            return String::new();
        }
    }
}

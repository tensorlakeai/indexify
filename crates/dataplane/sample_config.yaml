# Indexify Dataplane Configuration
#
# Copy this file and adjust for your environment:
#   cp sample_config.yaml config.yaml
#   indexify-dataplane --config config.yaml

# ---------------------------------------------------------------------------
# General
# ---------------------------------------------------------------------------

# Environment name. Set to anything other than "local" to enable structured
# JSON logging (e.g., "staging", "production").
env: local

# Unique identifier for this executor (auto-generated UUID if not specified).
# executor_id: "executor-1"

# The control-plane gRPC server address. Must include a scheme.
server_addr: "http://localhost:8901"

# Top-level state directory. Container state, driver metadata, and logs are
# stored under this path. Default: ./dataplane-state
# state_dir: /var/lib/indexify

# ---------------------------------------------------------------------------
# TLS
# ---------------------------------------------------------------------------

tls:
  enabled: false
  # ca_cert_path: "/etc/certs/ca.pem"          # CA to verify server cert
  # client_cert_path: "/etc/certs/client.pem"  # Client cert (mTLS)
  # client_key_path: "/etc/certs/client-key.pem"  # Client key (mTLS)
  # domain_name: "indexify.example.com"         # Override TLS SNI

# ---------------------------------------------------------------------------
# Telemetry
# ---------------------------------------------------------------------------

# telemetry:
#   tracing_exporter: otlp                           # "stdout" or "otlp"
#   endpoint: "http://otel-collector:4317"            # OTLP collector endpoint
#   enable_metrics: true
#   metrics_interval: 10                              # seconds
#   instance_id: "dataplane-1"

# ---------------------------------------------------------------------------
# Process Drivers
# ---------------------------------------------------------------------------
# Separate drivers for function executors and sandbox containers.
# This allows using different isolation backends (e.g., gVisor for functions
# and Firecracker for sandboxes).
#
# Options: "fork_exec" (default), "docker", "firecracker"

# --- fork_exec (default â€” no configuration needed) ---
function_driver:
  type: fork_exec

sandbox_driver:
  type: fork_exec

# --- Docker driver ---
# function_driver:
#   type: docker
#   address: "unix:///var/run/docker.sock"     # Docker daemon address
#   runtime: runsc                             # OCI runtime (e.g., runsc for gVisor)
#   network: bridge                            # Docker network mode
#   binds:                                     # Volume bind mounts
#     - "/host/path:/container/path:ro"
#   runsc_root: /var/run/docker/runtime-runc/moby   # runsc state dir (--root)
#   snapshot_local_dir: /tmp/indexify-snapshots      # gVisor snapshot overlay tars

# --- Firecracker driver (requires --features firecracker) ---
# Launches each sandbox in an isolated microVM using Firecracker + KVM.
# Requires: firecracker binary, Linux kernel image, base rootfs, CNI network,
# and an LVM thin pool for per-VM copy-on-write block devices.
#
# sandbox_driver:
#   type: firecracker
#
#   # -- Required ----------------------------------------------------------
#   kernel_image_path: /opt/firecracker/vmlinux-6.1    # Linux kernel (vmlinux)
#   base_rootfs_image: /opt/firecracker/rootfs.ext4    # Base guest OS rootfs
#   cni_network_name: indexify-fc                      # CNI conflist "name"
#   guest_gateway: "192.168.30.1"                      # Gateway IP for guests
#
#   # LVM thin provisioning for per-VM COW devices.
#   # Each VM gets a thin logical volume as its dm-snapshot COW device.
#   # Setup (one-time):
#   #   pvcreate /dev/nvme1n1            # or use a loopback: see README
#   #   vgcreate indexify-vg /dev/nvme1n1
#   #   lvcreate -L 100G -T indexify-vg/thinpool
#   lvm_volume_group: indexify-vg
#   lvm_thin_pool: thinpool
#
#   # -- Optional (defaults shown) ----------------------------------------
#   # firecracker_binary: firecracker        # Path or PATH lookup
#   # default_rootfs_size_bytes: 1073741824  # Per-VM COW LV size (1 GiB)
#   # cni_bin_path: /opt/cni/bin             # CNI plugin binaries
#   # guest_netmask: "255.255.255.0"         # Guest network mask
#   # default_vcpu_count: 2                  # vCPUs per VM
#   # default_memory_mib: 512               # Memory per VM in MiB
#   # state_dir: /var/lib/indexify/firecracker   # VM metadata, sockets
#   # log_dir: /var/log/indexify/firecracker     # VM log files
#
# --- Mixed example: gVisor for functions, Firecracker for sandboxes ---
# function_driver:
#   type: docker
#   runtime: runsc
# sandbox_driver:
#   type: firecracker
#   kernel_image_path: /opt/firecracker/vmlinux-6.1
#   base_rootfs_image: /opt/firecracker/rootfs.ext4
#   cni_network_name: indexify-fc
#   guest_gateway: "192.168.30.1"
#   lvm_volume_group: indexify-vg
#   lvm_thin_pool: thinpool

# ---------------------------------------------------------------------------
# Function Executor
# ---------------------------------------------------------------------------

# function_executor:
#   code_cache_path: /tmp/indexify_code_cache    # Cache dir for app code
#   fe_binary_path: /usr/local/bin/function-executor  # FE binary path

# Default container image when no image resolver is configured.
# default_function_image: "python:3.10-slim"

# Only accept allocations for these functions (empty = accept all).
# Format: "namespace:application:function" or "namespace:application:function:version"
# function_allowlist:
#   - "default:my-app:my-function"

# Labels advertised to the control plane for scheduling.
# labels:
#   gpu: "a100"
#   region: "us-east-1"

# ---------------------------------------------------------------------------
# HTTP Proxy
# ---------------------------------------------------------------------------
# Receives requests from sandbox-proxy with Tensorlake-Sandbox-Id header
# and routes them to the correct container.

http_proxy:
  port: 8095
  listen_addr: "0.0.0.0"
  # Address advertised to the server (defaults to hostname:port).
  # For local dev, set to 127.0.0.1:port so sandbox-proxy can reach this.
  # advertise_address: "127.0.0.1:8095"

  # Upstream connection tuning (container connections):
  # upstream:
  #   idle_timeout_secs: 55
  #   keepalive_idle_secs: 30
  #   keepalive_interval_secs: 10
  #   keepalive_count: 3
  #   connection_timeout_secs: 10
  #   read_timeout_secs: 60
  #   write_timeout_secs: 60

# ---------------------------------------------------------------------------
# Monitoring
# ---------------------------------------------------------------------------

monitoring:
  port: 8100
  listen_addr: "0.0.0.0"

# ---------------------------------------------------------------------------
# Resource Overrides
# ---------------------------------------------------------------------------
# Override auto-detected host resources (useful for testing or cgroup limits).
#
# resource_overrides:
#   cpu_count: 4
#   memory_bytes: 8589934592    # 8 GiB
#   disk_bytes: 107374182400    # 100 GiB
